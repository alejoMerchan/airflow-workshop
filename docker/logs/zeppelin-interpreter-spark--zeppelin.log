 WARN [2020-02-27 17:43:22,852] ({main} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2020-02-27 17:43:23,233] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.2.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2020-02-27 17:43:23,277] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.20.0.3:37851
 INFO [2020-02-27 17:43:23,281] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 37851
 INFO [2020-02-27 17:43:23,284] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 37851
 INFO [2020-02-27 17:43:24,294] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.20.0.3, callbackPort: 38741, callbackInfo: CallbackInfo(host:172.20.0.3, port:37851)
 INFO [2020-02-27 17:43:24,646] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-27 17:43:24,653] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-02-27 17:43:24,658] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-02-27 17:43:24,664] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-02-27 17:43:24,672] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-02-27 17:43:24,676] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2020-02-27 17:43:24,929] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-27 17:43:24,984] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-27 17:43:24,985] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-27 17:43:24,988] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-27 17:43:24,996] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-27 17:43:24,997] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2020-02-27 17:43:25,007] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200220-160006_1976879117 started by scheduler interpreter_1181365328
 INFO [2020-02-27 17:43:29,645] ({pool-2-thread-2} OldSparkInterpreter.java[createSparkSession]:311) - ------ Create new SparkSession spark://spark-master:7077 -------
 INFO [2020-02-27 17:43:29,964] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Running Spark version 2.4.0
 INFO [2020-02-27 17:43:29,994] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2020-02-27 17:43:30,079] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2020-02-27 17:43:30,080] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2020-02-27 17:43:30,080] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2020-02-27 17:43:30,081] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2020-02-27 17:43:30,082] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2020-02-27 17:43:30,413] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 39463.
 INFO [2020-02-27 17:43:30,451] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2020-02-27 17:43:30,539] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2020-02-27 17:43:30,554] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2020-02-27 17:43:30,556] ({pool-2-thread-2} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2020-02-27 17:43:30,581] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-cda811ea-2c98-4532-a535-568983e4cc28
 INFO [2020-02-27 17:43:30,604] ({pool-2-thread-2} Logging.scala[logInfo]:54) - MemoryStore started with capacity 366.3 MB
 INFO [2020-02-27 17:43:30,625] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2020-02-27 17:43:30,757] ({pool-2-thread-2} Log.java[initialized]:192) - Logging initialized @9710ms
 INFO [2020-02-27 17:43:30,868] ({pool-2-thread-2} Server.java[doStart]:351) - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
 INFO [2020-02-27 17:43:30,888] ({pool-2-thread-2} Server.java[doStart]:419) - Started @9842ms
 INFO [2020-02-27 17:43:31,265] ({pool-2-thread-2} AbstractConnector.java[doStart]:278) - Started ServerConnector@24e0febf{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2020-02-27 17:43:31,267] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2020-02-27 17:43:31,299] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7edc70e3{/jobs,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,301] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1a3f860d{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,303] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@57a44fc0{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,305] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@66a9b6d8{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,307] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@c04bee{/stages,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,308] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@756fce79{/stages/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,312] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@66fae36{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,314] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@245179bc{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,316] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5fb47d1e{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,318] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2c2678c2{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,320] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@30cda4d3{/storage,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,321] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1ffeb7ef{/storage/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,323] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@63de6583{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,325] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7c21e152{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,326] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@21173939{/environment,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,329] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4bbca33b{/environment/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,331] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5bde25b2{/executors,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,334] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@288664ea{/executors/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,336] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@30405e32{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,338] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1e4b967a{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,349] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@3492d3b4{/static,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,351] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@7dd1764b{/,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,363] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5ff5a1a7{/api,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,366] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@51416c8d{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,369] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@90bdba9{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:31,374] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://zeppelin:4040
 INFO [2020-02-27 17:43:31,408] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Added JAR file:/zeppelin/interpreter/spark/spark-interpreter-0.8.2.jar at spark://zeppelin:39463/jars/spark-interpreter-0.8.2.jar with timestamp 1582825411407
 WARN [2020-02-27 17:43:31,476] ({pool-2-thread-2} Logging.scala[logWarning]:66) - Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.
 INFO [2020-02-27 17:43:31,489] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created default pool: default, schedulingMode: FIFO, minShare: 0, weight: 1
 INFO [2020-02-27 17:43:31,592] ({appclient-register-master-threadpool-0} Logging.scala[logInfo]:54) - Connecting to master spark://spark-master:7077...
 INFO [2020-02-27 17:43:31,649] ({netty-rpc-connection-0} TransportClientFactory.java[createClient]:267) - Successfully created connection to spark-master/172.20.0.5:7077 after 33 ms (0 ms spent in bootstraps)
 INFO [2020-02-27 17:43:31,863] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Connected to Spark cluster with app ID app-20200227174331-0000
 INFO [2020-02-27 17:43:31,874] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43395.
 INFO [2020-02-27 17:43:31,876] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Server created on zeppelin:43395
 INFO [2020-02-27 17:43:31,880] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2020-02-27 17:43:31,920] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Executor added: app-20200227174331-0000/0 on worker-20200227162505-172.20.0.6-38011 (172.20.0.6:38011) with 4 core(s)
 INFO [2020-02-27 17:43:31,927] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Granted executor ID app-20200227174331-0000/0 on hostPort 172.20.0.6:38011 with 4 core(s), 2.0 GB RAM
 INFO [2020-02-27 17:43:31,932] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Executor added: app-20200227174331-0000/1 on worker-20200227162505-172.20.0.7-37755 (172.20.0.7:37755) with 4 core(s)
 INFO [2020-02-27 17:43:31,933] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Granted executor ID app-20200227174331-0000/1 on hostPort 172.20.0.7:37755 with 4 core(s), 2.0 GB RAM
 INFO [2020-02-27 17:43:31,972] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, zeppelin, 43395, None)
 INFO [2020-02-27 17:43:31,984] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager zeppelin:43395 with 366.3 MB RAM, BlockManagerId(driver, zeppelin, 43395, None)
 INFO [2020-02-27 17:43:32,009] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, zeppelin, 43395, None)
 INFO [2020-02-27 17:43:32,015] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, zeppelin, 43395, None)
 INFO [2020-02-27 17:43:32,044] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Executor updated: app-20200227174331-0000/1 is now RUNNING
 INFO [2020-02-27 17:43:32,086] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Executor updated: app-20200227174331-0000/0 is now RUNNING
 INFO [2020-02-27 17:43:32,608] ({pool-2-thread-2} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1a477e56{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 17:43:32,690] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
 INFO [2020-02-27 17:43:32,754] ({pool-2-thread-2} OldSparkInterpreter.java[createSparkSession]:347) - Created Spark session with Hive support
 INFO [2020-02-27 17:43:38,284] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.7:36394) with ID 1
 INFO [2020-02-27 17:43:38,320] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.20.0.6:33432) with ID 0
 INFO [2020-02-27 17:43:39,009] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Registering block manager 172.20.0.7:46089 with 912.3 MB RAM, BlockManagerId(1, 172.20.0.7, 46089, None)
 INFO [2020-02-27 17:43:39,031] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Registering block manager 172.20.0.6:46003 with 912.3 MB RAM, BlockManagerId(0, 172.20.0.6, 46003, None)
 INFO [2020-02-27 17:43:44,972] ({pool-2-thread-2} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2020-02-27 17:43:44,984] ({pool-2-thread-2} OldSparkInterpreter.java[populateSparkWebUrl]:931) - Sending metadata to Zeppelin server: {message=Spark UI enabled, url=http://zeppelin:4040}
 INFO [2020-02-27 17:43:45,316] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200220-160006_1976879117 finished by scheduler interpreter_1181365328
 INFO [2020-02-27 18:05:36,068] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Executor updated: app-20200227174331-0000/1 is now LOST (worker lost)
 INFO [2020-02-27 18:05:36,076] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Executor app-20200227174331-0000/1 removed: worker lost
 INFO [2020-02-27 18:05:36,093] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Master removed worker worker-20200227162505-172.20.0.7-37755: 172.20.0.7:37755 got disassociated
ERROR [2020-02-27 18:05:36,095] ({dispatcher-event-loop-1} Logging.scala[logError]:70) - Lost executor 1 on 172.20.0.7: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
 INFO [2020-02-27 18:05:36,099] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Worker worker-20200227162505-172.20.0.7-37755 removed: 172.20.0.7:37755 got disassociated
 INFO [2020-02-27 18:05:36,776] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Executor updated: app-20200227174331-0000/0 is now LOST (worker lost)
 INFO [2020-02-27 18:05:36,780] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Executor app-20200227174331-0000/0 removed: worker lost
 INFO [2020-02-27 18:05:36,781] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Master removed worker worker-20200227162505-172.20.0.6-38011: 172.20.0.6:38011 got disassociated
 INFO [2020-02-27 18:05:36,781] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Worker worker-20200227162505-172.20.0.6-38011 removed: 172.20.0.6:38011 got disassociated
 INFO [2020-02-27 18:05:36,796] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Executor lost: 1 (epoch 0)
 INFO [2020-02-27 18:05:36,807] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Trying to remove executor 1 from BlockManagerMaster.
 INFO [2020-02-27 18:05:36,808] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removal of executor 1 requested
 INFO [2020-02-27 18:05:36,811] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removing block manager BlockManagerId(1, 172.20.0.7, 46089, None)
 INFO [2020-02-27 18:05:36,813] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Asked to remove non-existent executor 1
 INFO [2020-02-27 18:05:36,815] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Removed 1 successfully in removeExecutor
 INFO [2020-02-27 18:05:36,815] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Trying to remove executor 1 from BlockManagerMaster.
 INFO [2020-02-27 18:05:36,819] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Shuffle files lost for executor: 1 (epoch 0)
ERROR [2020-02-27 18:05:36,817] ({dispatcher-event-loop-1} Logging.scala[logError]:70) - Lost executor 0 on 172.20.0.6: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
 INFO [2020-02-27 18:05:36,821] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Executor lost: 0 (epoch 1)
 INFO [2020-02-27 18:05:36,822] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Handle removed worker worker-20200227162505-172.20.0.7-37755: 172.20.0.7:37755 got disassociated
 INFO [2020-02-27 18:05:36,839] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Trying to remove executor 0 from BlockManagerMaster.
 INFO [2020-02-27 18:05:36,844] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removing block manager BlockManagerId(0, 172.20.0.6, 46003, None)
 INFO [2020-02-27 18:05:36,845] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removal of executor 0 requested
 INFO [2020-02-27 18:05:36,846] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Removed 0 successfully in removeExecutor
 INFO [2020-02-27 18:05:36,846] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Trying to remove executor 0 from BlockManagerMaster.
 INFO [2020-02-27 18:05:36,848] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Shuffle files lost for executor: 0 (epoch 1)
 INFO [2020-02-27 18:05:36,846] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Asked to remove non-existent executor 0
 INFO [2020-02-27 18:05:36,850] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Handle removed worker worker-20200227162505-172.20.0.6-38011: 172.20.0.6:38011 got disassociated
 INFO [2020-02-27 18:05:36,850] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Shuffle files lost for worker worker-20200227162505-172.20.0.7-37755 on host 172.20.0.7
 INFO [2020-02-27 18:05:36,852] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Shuffle files lost for worker worker-20200227162505-172.20.0.6-38011 on host 172.20.0.6
 WARN [2020-02-27 18:05:46,882] ({dispatcher-event-loop-0} Logging.scala[logWarning]:66) - Connection to spark-master:7077 failed; waiting for master to reconnect...
 WARN [2020-02-27 18:05:46,883] ({dispatcher-event-loop-0} Logging.scala[logWarning]:66) - Disconnected from Spark cluster! Waiting for reconnection...
 WARN [2020-02-27 18:05:46,884] ({dispatcher-event-loop-0} Logging.scala[logWarning]:66) - Connection to spark-master:7077 failed; waiting for master to reconnect...
 INFO [2020-02-27 18:05:48,583] ({pool-1-thread-3} OldSparkInterpreter.java[close]:1243) - Close interpreter
 INFO [2020-02-27 18:05:48,589] ({pool-1-thread-3} AbstractConnector.java[doStop]:318) - Stopped Spark@24e0febf{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2020-02-27 18:05:48,593] ({pool-1-thread-3} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://zeppelin:4040
 INFO [2020-02-27 18:05:48,601] ({pool-1-thread-3} Logging.scala[logInfo]:54) - Shutting down all executors
 INFO [2020-02-27 18:05:48,602] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Asking each executor to shut down
 INFO [2020-02-27 18:05:48,616] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2020-02-27 18:05:48,711] ({pool-1-thread-3} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2020-02-27 18:05:48,713] ({pool-1-thread-3} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2020-02-27 18:05:48,715] ({pool-1-thread-3} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2020-02-27 18:05:48,718] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2020-02-27 18:05:48,724] ({pool-1-thread-3} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2020-02-27 18:05:48,740] ({pool-1-thread-3} RemoteInterpreterServer.java[shutdown]:209) - Shutting down...
 INFO [2020-02-27 18:05:50,858] ({Thread-1} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2020-02-27 18:05:50,864] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-e35dbb32-59dd-4480-99be-23d1397632b9
 INFO [2020-02-27 18:05:50,877] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-4d886a94-aa88-4610-b028-9eb8845aff23
 INFO [2020-02-27 18:05:50,884] ({Thread-1} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-b02efffb-3a08-45f7-a50e-bc1c95f2f212
 WARN [2020-02-27 20:16:17,956] ({main} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 INFO [2020-02-27 20:16:19,133] ({main} RemoteInterpreterServer.java[main]:261) - URL:jar:file:/zeppelin/interpreter/spark/spark-interpreter-0.8.2.jar!/org/apache/zeppelin/interpreter/remote/RemoteInterpreterServer.class
 INFO [2020-02-27 20:16:19,206] ({main} RemoteInterpreterServer.java[<init>]:162) - Launching ThriftServer at 172.22.0.3:38341
 INFO [2020-02-27 20:16:19,213] ({main} RemoteInterpreterServer.java[<init>]:166) - Starting remote interpreter server on port 38341
 INFO [2020-02-27 20:16:19,217] ({Thread-3} RemoteInterpreterServer.java[run]:203) - Starting remote interpreter server on port 38341
 INFO [2020-02-27 20:16:20,233] ({Thread-4} RemoteInterpreterUtils.java[registerInterpreter]:165) - callbackHost: 172.22.0.3, callbackPort: 37611, callbackInfo: CallbackInfo(host:172.22.0.3, port:38341)
 INFO [2020-02-27 20:16:21,179] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-27 20:16:21,235] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-02-27 20:16:21,252] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-02-27 20:16:21,304] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-02-27 20:16:21,353] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-02-27 20:16:21,367] ({pool-1-thread-1} RemoteInterpreterServer.java[createInterpreter]:311) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 WARN [2020-02-27 20:16:21,902] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-27 20:16:22,043] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-27 20:16:22,072] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-27 20:16:22,125] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-27 20:16:22,158] ({pool-1-thread-1} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-27 20:16:22,205] ({pool-1-thread-1} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 INFO [2020-02-27 20:16:22,264] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20200220-160006_1976879117 started by scheduler interpreter_817303035
 INFO [2020-02-27 20:16:34,030] ({pool-2-thread-5} OldSparkInterpreter.java[createSparkSession]:311) - ------ Create new SparkSession spark://spark-master:7077 -------
 INFO [2020-02-27 20:16:34,940] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Running Spark version 2.4.0
 INFO [2020-02-27 20:16:35,082] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Submitted application: Zeppelin
 INFO [2020-02-27 20:16:35,536] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2020-02-27 20:16:35,555] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2020-02-27 20:16:35,557] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2020-02-27 20:16:35,569] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2020-02-27 20:16:35,585] ({pool-2-thread-5} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2020-02-27 20:16:36,881] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 40531.
 INFO [2020-02-27 20:16:36,958] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2020-02-27 20:16:37,007] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2020-02-27 20:16:37,014] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2020-02-27 20:16:37,036] ({pool-2-thread-5} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2020-02-27 20:16:37,081] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-be91ce92-8b50-4aab-8146-4fc1b3b94412
 INFO [2020-02-27 20:16:37,147] ({pool-2-thread-5} Logging.scala[logInfo]:54) - MemoryStore started with capacity 366.3 MB
 INFO [2020-02-27 20:16:37,209] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2020-02-27 20:16:37,597] ({pool-2-thread-5} Log.java[initialized]:192) - Logging initialized @22870ms
 INFO [2020-02-27 20:16:37,863] ({pool-2-thread-5} Server.java[doStart]:351) - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
 INFO [2020-02-27 20:16:37,965] ({pool-2-thread-5} Server.java[doStart]:419) - Started @23238ms
 INFO [2020-02-27 20:16:38,024] ({pool-2-thread-5} AbstractConnector.java[doStart]:278) - Started ServerConnector@1e6a109d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
 INFO [2020-02-27 20:16:38,029] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2020-02-27 20:16:39,408] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@793b541e{/jobs,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,410] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6812ee0c{/jobs/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,413] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@9762c26{/jobs/job,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,417] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1b6a75be{/jobs/job/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,430] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@64778a51{/stages,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,435] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5cd89de5{/stages/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,464] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4201ae36{/stages/stage,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,467] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4adc5a41{/stages/stage/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,470] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@5632d32{/stages/pool,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,473] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@78b21d4f{/stages/pool/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,485] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@349fd92c{/storage,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,499] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1cb993ac{/storage/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,510] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@af37b4{/storage/rdd,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,516] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@681f1a8b{/storage/rdd/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,524] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2203f81d{/environment,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,544] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@72772b02{/environment/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,550] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@b9ca06f{/executors,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,556] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@1bc738d5{/executors/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,567] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@2639e8a0{/executors/threadDump,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,569] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6dddf85e{/executors/threadDump/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,594] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@32ca252{/static,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,597] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@6a1ebb08{/,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,603] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4cfceb6f{/api,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,607] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@49366c75{/jobs/job/kill,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,622] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@4c7fd91f{/stages/stage/kill,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:39,631] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://zeppelin:4040
 INFO [2020-02-27 20:16:39,760] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Added JAR file:/zeppelin/interpreter/spark/spark-interpreter-0.8.2.jar at spark://zeppelin:40531/jars/spark-interpreter-0.8.2.jar with timestamp 1582834599759
 WARN [2020-02-27 20:16:39,994] ({pool-2-thread-5} Logging.scala[logWarning]:66) - Fair Scheduler configuration file not found so jobs will be scheduled in FIFO order. To use fair scheduling, configure pools in fairscheduler.xml or set spark.scheduler.allocation.file to a file that contains the configuration.
 INFO [2020-02-27 20:16:40,013] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Created default pool: default, schedulingMode: FIFO, minShare: 0, weight: 1
 INFO [2020-02-27 20:16:40,149] ({appclient-register-master-threadpool-0} Logging.scala[logInfo]:54) - Connecting to master spark://spark-master:7077...
 INFO [2020-02-27 20:16:40,328] ({netty-rpc-connection-0} TransportClientFactory.java[createClient]:267) - Successfully created connection to spark-master/172.22.0.5:7077 after 111 ms (0 ms spent in bootstraps)
 INFO [2020-02-27 20:16:40,650] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Connected to Spark cluster with app ID app-20200227201640-0000
 INFO [2020-02-27 20:16:40,673] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35157.
 INFO [2020-02-27 20:16:40,678] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Server created on zeppelin:35157
 INFO [2020-02-27 20:16:40,684] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2020-02-27 20:16:40,737] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Executor added: app-20200227201640-0000/0 on worker-20200227201300-172.22.0.7-44215 (172.22.0.7:44215) with 4 core(s)
 INFO [2020-02-27 20:16:40,746] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Granted executor ID app-20200227201640-0000/0 on hostPort 172.22.0.7:44215 with 4 core(s), 2.0 GB RAM
 INFO [2020-02-27 20:16:40,766] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Executor added: app-20200227201640-0000/1 on worker-20200227201300-172.22.0.6-36511 (172.22.0.6:36511) with 4 core(s)
 INFO [2020-02-27 20:16:40,768] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Granted executor ID app-20200227201640-0000/1 on hostPort 172.22.0.6:36511 with 4 core(s), 2.0 GB RAM
 INFO [2020-02-27 20:16:40,840] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, zeppelin, 35157, None)
 INFO [2020-02-27 20:16:40,875] ({dispatcher-event-loop-3} Logging.scala[logInfo]:54) - Registering block manager zeppelin:35157 with 366.3 MB RAM, BlockManagerId(driver, zeppelin, 35157, None)
 INFO [2020-02-27 20:16:40,897] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, zeppelin, 35157, None)
 INFO [2020-02-27 20:16:40,912] ({pool-2-thread-5} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, zeppelin, 35157, None)
 INFO [2020-02-27 20:16:41,313] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Executor updated: app-20200227201640-0000/0 is now RUNNING
 INFO [2020-02-27 20:16:41,378] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Executor updated: app-20200227201640-0000/1 is now RUNNING
 INFO [2020-02-27 20:16:42,400] ({pool-2-thread-5} ContextHandler.java[doStart]:781) - Started o.s.j.s.ServletContextHandler@78c0e172{/metrics/json,null,AVAILABLE,@Spark}
 INFO [2020-02-27 20:16:42,503] ({pool-2-thread-5} Logging.scala[logInfo]:54) - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
 INFO [2020-02-27 20:16:42,664] ({pool-2-thread-5} OldSparkInterpreter.java[createSparkSession]:347) - Created Spark session with Hive support
 INFO [2020-02-27 20:17:04,720] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.22.0.7:33854) with ID 0
 INFO [2020-02-27 20:17:04,762] ({dispatcher-event-loop-2} Logging.scala[logInfo]:54) - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.22.0.6:56874) with ID 1
 INFO [2020-02-27 20:17:07,062] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.22.0.6:34581 with 912.3 MB RAM, BlockManagerId(1, 172.22.0.6, 34581, None)
 INFO [2020-02-27 20:17:07,227] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.22.0.7:40361 with 912.3 MB RAM, BlockManagerId(0, 172.22.0.7, 40361, None)
 INFO [2020-02-27 20:17:22,018] ({pool-2-thread-5} SparkShims.java[loadShims]:62) - Initializing shims for Spark 2.x
 INFO [2020-02-27 20:17:22,061] ({pool-2-thread-5} OldSparkInterpreter.java[populateSparkWebUrl]:931) - Sending metadata to Zeppelin server: {message=Spark UI enabled, url=http://zeppelin:4040}
 INFO [2020-02-27 20:17:22,879] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20200220-160006_1976879117 finished by scheduler interpreter_817303035
