 WARN [2020-02-19 05:35:59,478] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 05:35:59,582] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 05:35:59,584] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 05:35:59,593] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 05:35:59,598] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 05:35:59,673] ({main} Log.java[initialized]:193) - Logging initialized @1255ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 05:36:00,007] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 05:36:00,221] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 05:36:00,424] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 05:36:00,427] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 05:36:07,003] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 05:36:07,052] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 05:36:07,056] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 05:36:07,063] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-02-19 05:36:08,445] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 05:36:08,487] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 05:36:08,490] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 05:36:08,718] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 05:36:08,729] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 05:36:08,822] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 05:36:08,846] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 05:36:08,865] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 05:36:08,895] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 05:36:08,915] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 05:36:08,947] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 05:36:09,282] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 05:36:09,318] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 05:36:09,343] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 05:36:09,387] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 05:36:09,399] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 05:36:09,418] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 05:36:09,441] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 05:36:09,447] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 05:36:09,467] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 05:36:09,485] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 05:36:09,505] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 05:36:09,517] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 05:36:09,528] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 05:36:09,544] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 05:36:09,556] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 05:36:09,573] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 05:36:09,591] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 05:36:09,604] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 05:36:09,622] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 05:36:10,101] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 05:36:10,109] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 05:36:10,122] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 05:36:10,135] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 05:36:10,143] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 05:36:10,157] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 05:36:10,160] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 05:36:10,163] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 05:36:10,186] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 05:36:10,193] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 05:36:10,196] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 05:36:10,208] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 05:36:10,231] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 05:36:10,249] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 05:36:10,275] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 05:36:10,276] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 05:36:10,279] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 05:36:10,287] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 05:36:10,289] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 05:36:10,292] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 05:36:10,305] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 05:36:10,308] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 05:36:10,457] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 05:36:11,488] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 05:36:11,756] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 05:36:12,528] ({main} GitNotebookRepo.java[<init>]:67) - Git repo /zeppelin/notebook/.git does not exist, creating a new one
 INFO [2020-02-19 05:36:12,739] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 05:36:13,347] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 05:36:13,354] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 05:36:13,359] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 05:36:13,609] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 05:36:13,642] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 05:36:13,834] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 05:36:13,846] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 05:36:13,849] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 05:36:13,857] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 05:36:13,858] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 05:36:13,859] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 05:36:13,861] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 05:36:14,286] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 05:36:14,287] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 05:36:14,288] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 05:36:14,290] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,334] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 05:36:14,339] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,357] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 05:36:14,364] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,381] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 05:36:14,388] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,407] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 05:36:14,409] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,416] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 05:36:14,418] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,431] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 05:36:14,433] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 05:36:14,434] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 05:36:14,678] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 7 notebooks took 242ms
 INFO [2020-02-19 05:36:14,680] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 7 indexed in 0s
 INFO [2020-02-19 05:36:14,685] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 05:36:14,688] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 05:36:14,696] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 05:36:17,249] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 05:36:17,273] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@762637be{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 05:36:17,274] ({main} Server.java[doStart]:407) - Started @18877ms
 INFO [2020-02-19 05:36:17,275] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 05:37:09,197] ({qtp395629617-15} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 05:37:09,389] ({qtp395629617-17} NotebookServer.java[onOpen]:151) - New connection from 192.168.240.1 : 35838
 INFO [2020-02-19 05:38:41,671] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 05:38:41,687] ({qtp395629617-10} NotebookServer.java[onClose]:372) - Closed connection to 192.168.240.1 : 35838. (1000) null
 INFO [2020-02-19 05:38:41,688] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@762637be{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 05:38:41,690] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 05:38:42,620] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 05:38:42,623] ({Thread-37} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 05:38:42,623] ({Thread-38} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 05:38:42,624] ({Thread-39} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 05:38:42,624] ({Thread-36} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 05:38:42,633] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 05:38:42,634] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 05:38:42,632] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 05:38:42,632] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 05:38:42,632] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 05:38:42,632] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 05:38:42,632] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 05:38:42,632] ({Thread-42} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 05:38:42,631] ({Thread-40} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 05:38:42,630] ({Thread-43} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 05:38:42,630] ({Thread-41} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 05:38:42,642] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 05:38:42,642] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 05:38:42,642] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 05:38:42,642] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 05:38:42,642] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 05:38:42,642] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 05:38:42,641] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 05:38:42,641] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 05:38:42,639] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 05:38:42,639] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 05:38:42,639] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 05:38:42,639] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 05:38:42,639] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 05:38:42,639] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 05:38:42,638] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 05:38:42,638] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 05:38:42,637] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 05:38:42,637] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 05:38:42,637] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 05:38:42,636] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 05:38:42,636] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 05:38:42,636] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 05:38:42,636] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 05:38:42,635] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 05:38:42,635] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 05:38:42,634] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 05:38:42,634] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 05:38:42,634] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 05:38:42,633] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 05:38:42,666] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 05:38:45,680] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
 WARN [2020-02-19 06:40:20,254] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 06:40:20,321] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 06:40:20,322] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 06:40:20,323] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 06:40:20,329] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 06:40:20,369] ({main} Log.java[initialized]:193) - Logging initialized @1044ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 06:40:20,650] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 06:40:20,797] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 06:40:20,990] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 06:40:20,997] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 06:40:28,093] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 06:40:28,148] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 06:40:28,149] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 06:40:28,154] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 600000ms
 INFO [2020-02-19 06:40:29,428] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 06:40:29,455] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 06:40:29,469] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 06:40:29,640] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 06:40:29,666] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 06:40:29,813] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 06:40:29,858] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 06:40:29,879] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 06:40:29,890] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 06:40:29,919] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 06:40:29,945] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 06:40:30,325] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 06:40:30,334] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 06:40:30,397] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 06:40:30,402] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 06:40:30,413] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 06:40:30,427] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 06:40:30,455] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 06:40:30,463] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 06:40:30,486] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 06:40:30,519] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 06:40:30,554] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 06:40:30,579] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 06:40:30,644] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 06:40:30,667] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 06:40:30,681] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 06:40:30,691] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 06:40:30,700] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 06:40:30,715] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 06:40:30,722] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:40:30,868] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 06:40:30,888] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 06:40:30,897] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 06:40:30,912] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 06:40:30,927] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 06:40:30,934] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 06:40:30,937] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 06:40:30,939] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 06:40:30,961] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 06:40:30,967] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 06:40:30,973] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 06:40:30,977] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 06:40:30,995] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 06:40:31,001] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 06:40:31,018] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 06:40:31,028] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 06:40:31,033] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 06:40:31,037] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 06:40:31,041] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 06:40:31,042] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 06:40:31,043] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 06:40:31,048] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 06:40:31,147] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:40:32,101] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 06:40:32,287] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 06:40:32,624] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 06:40:32,924] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 06:40:32,933] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 06:40:32,939] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 06:40:33,082] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 06:40:33,140] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 06:40:33,186] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 06:40:33,192] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 06:40:33,194] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 06:40:33,197] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 06:40:33,198] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 06:40:33,199] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 06:40:33,200] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 06:40:33,844] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 06:40:33,850] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 06:40:33,851] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 06:40:33,852] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:33,944] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 06:40:33,947] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:33,988] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 06:40:33,996] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:34,025] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 06:40:34,035] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:34,076] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 06:40:34,077] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:34,085] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 06:40:34,086] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:34,110] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 06:40:34,113] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:40:34,115] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 06:40:34,466] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 7 notebooks took 350ms
 INFO [2020-02-19 06:40:34,467] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 7 indexed in 0s
 INFO [2020-02-19 06:40:34,470] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 06:40:34,475] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 06:40:34,479] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 06:40:36,620] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:40:36,644] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@5dd903be{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:40:36,646] ({main} Server.java[doStart]:407) - Started @17324ms
 INFO [2020-02-19 06:40:36,647] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 06:40:44,625] ({qtp395629617-11} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:40:44,744] ({qtp395629617-14} NotebookServer.java[onOpen]:151) - New connection from 172.21.0.1 : 34512
 INFO [2020-02-19 06:41:38,830] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 06:41:38,842] ({qtp395629617-14} NotebookServer.java[onClose]:372) - Closed connection to 172.21.0.1 : 34512. (1000) null
 INFO [2020-02-19 06:41:38,845] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@5dd903be{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:41:38,847] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 06:41:40,014] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:41:40,016] ({Thread-37} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:41:40,016] ({Thread-36} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:41:40,017] ({Thread-42} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:41:40,018] ({Thread-41} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:41:40,017] ({Thread-38} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:41:40,017] ({Thread-40} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:41:40,023] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:41:40,017] ({Thread-39} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:41:40,024] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:41:40,027] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:41:40,023] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:41:40,023] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:41:40,023] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:41:40,022] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:41:40,022] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:41:40,022] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:41:40,022] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:41:40,021] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:41:40,021] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:41:40,021] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:41:40,020] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:41:40,020] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:41:40,020] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:41:40,020] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:41:40,020] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:41:40,020] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:41:40,020] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:41:40,019] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:41:40,019] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:41:40,018] ({Thread-43} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:41:40,030] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:41:40,028] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:41:40,027] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:41:40,026] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:41:40,026] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:41:40,026] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:41:40,026] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:41:40,026] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:41:40,025] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:41:40,025] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:41:40,025] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:41:40,025] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:41:40,025] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:41:40,025] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:41:40,050] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 06:41:43,064] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
 WARN [2020-02-19 06:42:51,273] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 06:42:51,347] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 06:42:51,348] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 06:42:51,349] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 06:42:51,356] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 06:42:51,416] ({main} Log.java[initialized]:193) - Logging initialized @1153ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 06:42:51,664] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 06:42:51,948] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 06:42:52,169] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 06:42:52,174] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 06:42:57,393] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 06:42:57,435] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 06:42:57,442] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 06:42:57,448] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 600000ms
 INFO [2020-02-19 06:42:58,242] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 06:42:58,264] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 06:42:58,275] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 06:42:58,406] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 06:42:58,408] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 06:42:58,455] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 06:42:58,466] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 06:42:58,477] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 06:42:58,501] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 06:42:58,528] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 06:42:58,546] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 06:42:58,704] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 06:42:58,721] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 06:42:58,729] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 06:42:58,743] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 06:42:58,757] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 06:42:58,765] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 06:42:58,773] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 06:42:58,781] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 06:42:58,790] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 06:42:58,803] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 06:42:58,808] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 06:42:58,811] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 06:42:58,818] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 06:42:58,822] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 06:42:58,837] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 06:42:58,846] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 06:42:58,852] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 06:42:58,857] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 06:42:58,871] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:42:59,164] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 06:42:59,168] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 06:42:59,177] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 06:42:59,193] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 06:42:59,196] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 06:42:59,198] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 06:42:59,215] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 06:42:59,216] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 06:42:59,224] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 06:42:59,226] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 06:42:59,227] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 06:42:59,230] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 06:42:59,231] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 06:42:59,241] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 06:42:59,249] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 06:42:59,253] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 06:42:59,257] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 06:42:59,259] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 06:42:59,262] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 06:42:59,269] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 06:42:59,279] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 06:42:59,284] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 06:42:59,422] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:43:00,030] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 06:43:00,248] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 06:43:00,599] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 06:43:00,728] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 06:43:00,729] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 06:43:00,730] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 06:43:00,777] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 06:43:00,786] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 06:43:00,818] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 06:43:00,820] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 06:43:00,822] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 06:43:00,824] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 06:43:00,825] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 06:43:00,826] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 06:43:00,827] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 06:43:01,042] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 06:43:01,043] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 06:43:01,044] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 06:43:01,046] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,069] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 06:43:01,071] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,084] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 06:43:01,085] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,098] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 06:43:01,100] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,113] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 06:43:01,115] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,122] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 06:43:01,123] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,131] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 06:43:01,133] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:43:01,134] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 06:43:01,312] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 7 notebooks took 177ms
 INFO [2020-02-19 06:43:01,313] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 7 indexed in 0s
 INFO [2020-02-19 06:43:01,316] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 06:43:01,318] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 06:43:01,322] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 06:43:03,201] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:43:03,215] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:43:03,216] ({main} Server.java[doStart]:407) - Started @12964ms
 INFO [2020-02-19 06:43:03,217] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 06:43:52,281] ({qtp395629617-10} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:43:52,399] ({qtp395629617-12} NotebookServer.java[onOpen]:151) - New connection from 172.22.0.1 : 45288
 INFO [2020-02-19 06:44:33,630] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 06:44:33,644] ({qtp395629617-14} NotebookServer.java[onClose]:372) - Closed connection to 172.22.0.1 : 45288. (1000) null
 INFO [2020-02-19 06:44:33,647] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:44:33,648] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 06:44:34,584] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:44:34,587] ({Thread-37} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:44:34,588] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:44:34,587] ({Thread-41} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:44:34,587] ({Thread-42} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:44:34,587] ({Thread-40} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:44:34,587] ({Thread-36} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:44:34,587] ({Thread-38} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:44:34,596] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:44:34,596] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:44:34,596] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:44:34,595] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:44:34,595] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:44:34,594] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:44:34,594] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:44:34,594] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:44:34,594] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:44:34,593] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:44:34,592] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:44:34,592] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:44:34,592] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:44:34,591] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:44:34,591] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:44:34,591] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:44:34,591] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:44:34,591] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:44:34,590] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:44:34,590] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:44:34,590] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:44:34,589] ({Thread-39} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:44:34,589] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:44:34,589] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:44:34,588] ({Thread-43} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:44:34,588] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:44:34,601] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:44:34,601] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:44:34,599] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:44:34,599] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:44:34,599] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:44:34,598] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:44:34,598] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:44:34,598] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:44:34,598] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:44:34,597] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:44:34,596] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:44:34,633] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 06:44:37,650] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
 WARN [2020-02-19 06:45:06,161] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 06:45:06,240] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 06:45:06,243] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 06:45:06,244] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 06:45:06,257] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 06:45:06,300] ({main} Log.java[initialized]:193) - Logging initialized @1073ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 06:45:06,553] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 06:45:06,674] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 06:45:06,828] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 06:45:06,832] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 06:45:11,941] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 06:45:12,003] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 06:45:12,006] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 06:45:12,011] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-02-19 06:45:13,091] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 06:45:13,145] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 06:45:13,157] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 06:45:13,398] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 06:45:13,407] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 06:45:13,469] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 06:45:13,495] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 06:45:13,508] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 06:45:13,527] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 06:45:13,544] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 06:45:13,576] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 06:45:13,835] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 06:45:13,852] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 06:45:13,866] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 06:45:13,881] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 06:45:13,904] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 06:45:13,910] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 06:45:13,919] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 06:45:13,934] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 06:45:13,942] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 06:45:13,948] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 06:45:13,958] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 06:45:13,969] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 06:45:13,979] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 06:45:13,996] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 06:45:14,008] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 06:45:14,014] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 06:45:14,017] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 06:45:14,028] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 06:45:14,042] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:45:14,243] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 06:45:14,256] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 06:45:14,258] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 06:45:14,285] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 06:45:14,297] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 06:45:14,302] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 06:45:14,304] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 06:45:14,312] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 06:45:14,318] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 06:45:14,329] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 06:45:14,335] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 06:45:14,339] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 06:45:14,341] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 06:45:14,344] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 06:45:14,350] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 06:45:14,358] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 06:45:14,363] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 06:45:14,367] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 06:45:14,369] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 06:45:14,370] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 06:45:14,372] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 06:45:14,379] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 06:45:14,477] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:45:14,945] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 06:45:15,066] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 06:45:15,524] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 06:45:15,882] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 06:45:15,886] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 06:45:15,890] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 06:45:16,054] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 06:45:16,063] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 06:45:16,085] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 06:45:16,087] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 06:45:16,090] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 06:45:16,092] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 06:45:16,093] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 06:45:16,095] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 06:45:16,096] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 06:45:17,059] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 06:45:17,091] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 06:45:17,111] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 06:45:17,122] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,303] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 06:45:17,321] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,451] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 06:45:17,454] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,575] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 06:45:17,596] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,680] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 06:45:17,687] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,743] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 06:45:17,753] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,848] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 06:45:17,868] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:45:17,878] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 06:45:18,307] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 7 notebooks took 419ms
 INFO [2020-02-19 06:45:18,309] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 7 indexed in 0s
 INFO [2020-02-19 06:45:18,312] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 06:45:18,316] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 06:45:18,324] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 06:45:21,104] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:45:21,141] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:45:21,142] ({main} Server.java[doStart]:407) - Started @15919ms
 INFO [2020-02-19 06:45:21,145] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 06:45:24,246] ({qtp395629617-12} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:45:24,407] ({qtp395629617-15} NotebookServer.java[onOpen]:151) - New connection from 172.23.0.1 : 49408
 INFO [2020-02-19 06:45:27,103] ({qtp395629617-15} NotebookServer.java[onClose]:372) - Closed connection to 172.23.0.1 : 49408. (1001) null
 WARN [2020-02-19 06:45:27,353] ({qtp395629617-17} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:45:27,395] ({qtp395629617-10} NotebookServer.java[onOpen]:151) - New connection from 172.23.0.1 : 49420
 INFO [2020-02-19 06:45:34,929] ({qtp395629617-17} NotebookServer.java[onClose]:372) - Closed connection to 172.23.0.1 : 49420. (1001) null
 WARN [2020-02-19 06:45:35,139] ({qtp395629617-15} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:45:35,172] ({qtp395629617-13} NotebookServer.java[onOpen]:151) - New connection from 172.23.0.1 : 49430
 INFO [2020-02-19 06:45:36,888] ({qtp395629617-17} NotebookServer.java[onClose]:372) - Closed connection to 172.23.0.1 : 49430. (1001) null
 WARN [2020-02-19 06:45:37,088] ({qtp395629617-15} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:45:37,128] ({qtp395629617-17} NotebookServer.java[onOpen]:151) - New connection from 172.23.0.1 : 49434
 INFO [2020-02-19 06:48:45,779] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 06:48:45,791] ({qtp395629617-16} NotebookServer.java[onClose]:372) - Closed connection to 172.23.0.1 : 49434. (1000) null
 INFO [2020-02-19 06:48:45,792] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@12e0f1cb{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:48:45,795] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 06:48:47,023] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:48:47,025] ({Thread-38} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:48:47,026] ({Thread-41} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:48:47,025] ({Thread-37} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:48:47,027] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:48:47,027] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:48:47,027] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:48:47,031] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:48:47,027] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:48:47,026] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:48:47,026] ({Thread-43} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:48:47,026] ({Thread-42} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:48:47,026] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:48:47,025] ({Thread-36} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:48:47,026] ({Thread-40} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:48:47,026] ({Thread-39} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:48:47,039] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:48:47,039] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:48:47,039] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:48:47,039] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:48:47,038] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:48:47,037] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:48:47,036] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:48:47,036] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:48:47,036] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:48:47,035] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:48:47,035] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:48:47,035] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:48:47,035] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:48:47,034] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:48:47,034] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:48:47,034] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:48:47,034] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:48:47,033] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:48:47,033] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:48:47,033] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:48:47,033] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:48:47,032] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:48:47,032] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:48:47,029] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:48:47,029] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:48:47,028] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:48:47,028] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:48:47,043] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:48:47,042] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:48:47,062] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 06:48:50,080] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
 WARN [2020-02-19 06:49:15,663] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 06:49:15,752] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 06:49:15,753] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 06:49:15,753] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 06:49:15,760] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 06:49:15,815] ({main} Log.java[initialized]:193) - Logging initialized @1582ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 06:49:16,091] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 06:49:16,354] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 06:49:16,600] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 06:49:16,603] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 06:49:21,829] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 06:49:21,936] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 06:49:21,937] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 06:49:21,965] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 600000ms
 INFO [2020-02-19 06:49:23,181] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 06:49:23,216] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 06:49:23,225] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 06:49:23,386] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 06:49:23,392] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 06:49:23,499] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 06:49:23,508] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 06:49:23,519] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 06:49:23,534] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 06:49:23,552] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 06:49:23,591] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 06:49:23,739] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 06:49:23,748] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 06:49:23,764] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 06:49:23,775] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 06:49:23,780] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 06:49:23,785] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 06:49:23,798] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 06:49:23,810] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 06:49:23,816] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 06:49:23,831] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 06:49:23,872] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 06:49:23,902] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 06:49:23,921] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 06:49:23,928] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 06:49:23,942] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 06:49:23,946] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 06:49:23,949] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 06:49:23,967] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 06:49:23,976] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:49:24,269] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 06:49:24,274] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 06:49:24,282] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 06:49:24,292] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 06:49:24,300] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 06:49:24,303] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 06:49:24,306] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 06:49:24,307] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 06:49:24,319] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 06:49:24,322] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 06:49:24,329] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 06:49:24,332] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 06:49:24,337] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 06:49:24,341] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 06:49:24,343] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 06:49:24,346] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 06:49:24,350] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 06:49:24,357] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 06:49:24,359] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 06:49:24,360] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 06:49:24,361] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 06:49:24,365] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 06:49:24,534] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:49:25,400] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 06:49:25,707] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 06:49:26,270] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 06:49:26,697] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 06:49:26,698] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 06:49:26,700] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 06:49:26,789] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 06:49:26,797] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 06:49:26,817] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 06:49:26,820] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 06:49:26,822] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 06:49:26,825] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 06:49:26,826] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 06:49:26,827] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 06:49:26,828] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 06:49:27,110] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 06:49:27,111] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 06:49:27,112] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 06:49:27,114] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,141] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 06:49:27,144] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,164] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 06:49:27,168] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,184] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 06:49:27,187] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,203] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 06:49:27,206] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,214] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 06:49:27,215] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,226] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 06:49:27,228] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:49:27,229] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 06:49:27,564] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 7 notebooks took 334ms
 INFO [2020-02-19 06:49:27,565] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 7 indexed in 0s
 INFO [2020-02-19 06:49:27,569] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 06:49:27,575] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 06:49:27,584] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 06:49:31,342] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:49:31,379] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@79a41e8{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:49:31,381] ({main} Server.java[doStart]:407) - Started @17156ms
 INFO [2020-02-19 06:49:31,382] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 06:51:06,483] ({qtp395629617-11} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:51:06,639] ({qtp395629617-17} NotebookServer.java[onOpen]:151) - New connection from 172.24.0.1 : 60932
 INFO [2020-02-19 06:57:06,246] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 06:57:06,262] ({qtp395629617-15} NotebookServer.java[onClose]:372) - Closed connection to 172.24.0.1 : 60932. (1000) null
 INFO [2020-02-19 06:57:06,265] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@79a41e8{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:57:06,266] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 06:57:07,195] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:57:07,197] ({Thread-36} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:57:07,198] ({Thread-38} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:57:07,200] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:57:07,200] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:57:07,200] ({Thread-43} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:57:07,200] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:57:07,200] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:57:07,199] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:57:07,206] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:57:07,199] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:57:07,199] ({Thread-41} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:57:07,199] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 06:57:07,198] ({Thread-37} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 06:57:07,209] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:57:07,210] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:57:07,199] ({Thread-42} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 06:57:07,198] ({Thread-39} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 06:57:07,199] ({Thread-40} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 06:57:07,217] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:57:07,217] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:57:07,212] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 06:57:07,212] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:57:07,211] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:57:07,210] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:57:07,210] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:57:07,209] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:57:07,209] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:57:07,209] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 06:57:07,206] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 06:57:07,206] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:57:07,206] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 06:57:07,206] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 06:57:07,204] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 06:57:07,204] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 06:57:07,204] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 06:57:07,203] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 06:57:07,203] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 06:57:07,203] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 06:57:07,203] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 06:57:07,202] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 06:57:07,202] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 06:57:07,201] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 06:57:07,201] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 06:57:07,201] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 06:57:07,230] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 06:57:10,253] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
 WARN [2020-02-19 06:57:41,514] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 06:57:41,584] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 06:57:41,586] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 06:57:41,587] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 06:57:41,592] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 06:57:41,631] ({main} Log.java[initialized]:193) - Logging initialized @1315ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 06:57:41,851] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 06:57:41,952] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 06:57:42,111] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 06:57:42,126] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 06:57:47,218] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 06:57:47,291] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 06:57:47,292] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 06:57:47,321] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-02-19 06:57:48,717] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 06:57:48,765] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 06:57:48,779] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 06:57:48,954] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 06:57:48,964] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 06:57:49,049] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 06:57:49,066] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 06:57:49,080] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 06:57:49,095] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 06:57:49,111] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 06:57:49,122] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 06:57:49,626] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 06:57:49,644] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 06:57:49,651] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 06:57:49,677] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 06:57:49,692] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 06:57:49,704] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 06:57:49,721] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 06:57:49,746] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 06:57:49,751] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 06:57:49,762] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 06:57:49,791] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 06:57:49,797] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 06:57:49,810] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 06:57:49,823] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 06:57:49,838] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 06:57:49,862] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 06:57:49,865] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 06:57:49,883] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 06:57:49,891] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:57:50,155] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 06:57:50,166] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 06:57:50,174] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 06:57:50,191] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 06:57:50,195] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 06:57:50,198] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 06:57:50,200] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 06:57:50,201] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 06:57:50,207] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 06:57:50,212] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 06:57:50,213] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 06:57:50,215] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 06:57:50,228] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 06:57:50,234] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 06:57:50,248] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 06:57:50,261] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 06:57:50,270] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 06:57:50,271] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 06:57:50,272] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 06:57:50,275] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 06:57:50,277] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 06:57:50,282] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 06:57:50,350] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:57:51,203] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 06:57:51,525] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 06:57:52,381] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 06:57:52,764] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 06:57:52,769] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 06:57:52,777] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 06:57:52,991] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 06:57:53,013] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 06:57:53,113] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 06:57:53,135] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 06:57:53,139] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 06:57:53,142] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 06:57:53,144] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 06:57:53,153] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 06:57:53,154] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 06:57:53,493] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 06:57:53,494] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 06:57:53,495] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 06:57:53,498] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,530] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 06:57:53,533] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,552] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 06:57:53,553] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,571] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 06:57:53,573] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,591] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 06:57:53,593] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,610] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 06:57:53,614] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,624] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 06:57:53,626] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 06:57:53,627] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 06:57:53,920] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 7 notebooks took 290ms
 INFO [2020-02-19 06:57:53,921] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 7 indexed in 0s
 INFO [2020-02-19 06:57:53,924] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 06:57:53,927] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 06:57:53,940] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 06:57:57,736] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 06:57:57,756] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@5dd903be{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 06:57:57,757] ({main} Server.java[doStart]:407) - Started @17445ms
 INFO [2020-02-19 06:57:57,758] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 06:58:02,679] ({qtp395629617-10} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 06:58:02,815] ({qtp395629617-15} NotebookServer.java[onOpen]:151) - New connection from 172.25.0.1 : 38228
 WARN [2020-02-19 06:59:12,240] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:12,242] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:12,243] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:12,245] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:12,246] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:12,247] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:16,945] ({qtp395629617-13} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:16,948] ({qtp395629617-13} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:16,950] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:16,951] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:16,952] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:16,953] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 06:59:16,954] ({qtp395629617-13} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 06:59:17,015] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 06:59:17,045] ({qtp395629617-13} FolderView.java[onNoteNameChanged]:205) - Note name changed: 2EZZ5HVRW -> test-1
 INFO [2020-02-19 06:59:17,047] ({qtp395629617-13} Folder.java[addNote]:185) - Add note 2EZZ5HVRW to folder /
 INFO [2020-02-19 06:59:17,054] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 06:59:17,303] ({qtp395629617-12} NotebookServer.java[sendNote]:828) - New operation from 172.25.0.1 : 38228 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 06:59:17,441] ({qtp395629617-12} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 06:59:17,459] ({qtp395629617-12} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:17,480] ({qtp395629617-12} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:17,490] ({qtp395629617-12} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:17,494] ({qtp395629617-12} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:17,495] ({qtp395629617-12} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 06:59:17,496] ({qtp395629617-12} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 06:59:17,606] ({qtp395629617-17} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2EZZ5HVRW
 INFO [2020-02-19 06:59:17,610] ({qtp395629617-17} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 06:59:17,611] ({qtp395629617-17} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 06:59:17,612] ({qtp395629617-17} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 06:59:17,613] ({qtp395629617-17} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 06:59:17,614] ({qtp395629617-17} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 06:59:17,615] ({qtp395629617-17} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 06:59:17,617] ({qtp395629617-17} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-02-19 07:00:31,437] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:00:50,363] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:00:50,522] ({qtp395629617-13} NotebookServer.java[broadcastNewParagraph]:688) - Broadcasting paragraph on run call instead of note.
 INFO [2020-02-19 07:00:50,542] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:00:50,571] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:00:50,577] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:00:50,579] ({pool-2-thread-2} ManagedInterpreterGroup.java[getOrCreateInterpreterProcess]:61) - Create InterpreterProcess for InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:00:50,581] ({pool-2-thread-2} ShellScriptLauncher.java[launch]:48) - Launching Interpreter: spark
 INFO [2020-02-19 07:00:50,661] ({pool-2-thread-2} SparkInterpreterLauncher.java[buildEnvFromProperties]:108) - Run Spark under non-secure mode as no keytab and principal is specified
 INFO [2020-02-19 07:00:50,674] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:115) - Thrift server for callback will start. Port: 33541
 INFO [2020-02-19 07:00:50,723] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:190) - Run interpreter process [/zeppelin/bin/interpreter.sh, -d, /zeppelin/interpreter/spark, -c, 172.25.0.3, -p, 33541, -r, :, -l, /usr/local/local-repo/spark, -g, spark]
 INFO [2020-02-19 07:00:55,733] ({pool-7-thread-1} RemoteInterpreterManagedProcess.java[callback]:123) - RemoteInterpreterServer Registered: CallbackInfo(host:172.25.0.3, port:39425)
 INFO [2020-02-19 07:00:55,913] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 07:00:56,117] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-02-19 07:00:56,121] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-02-19 07:00:56,125] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-02-19 07:00:56,131] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-02-19 07:00:56,139] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 07:00:56,142] ({pool-2-thread-2} RemoteInterpreter.java[call]:142) - Open RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 07:00:56,143] ({pool-2-thread-2} RemoteInterpreter.java[pushAngularObjectRegistryToRemote]:436) - Push local angular object registry from ZeppelinServer to remote interpreter group spark:shared_process
 INFO [2020-02-19 07:01:20,766] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:01:20,799] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:01:20,891] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:02:06,979] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:02:07,079] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:02:07,103] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:02:07,104] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:02:11,456] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text bankText: org.apache.spark.rdd.RDD[String] = /data/test.txt MapPartitionsRDD[3] at textFile at <console>:25
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, 172.25.0.7, executor 0): java.io.FileNotFoundException: File file:/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 48 elided
Caused by: java.io.FileNotFoundException: File file:/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:02:11,483] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:02:11,512] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:12:45,228] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 07:12:45,381] ({qtp395629617-13} NotebookServer.java[onClose]:372) - Closed connection to 172.25.0.1 : 38228. (1006) Disconnected
 INFO [2020-02-19 07:12:45,382] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@5dd903be{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 07:12:45,395] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 07:12:50,286] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 07:12:50,289] ({Thread-42} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 07:12:50,298] ({Thread-43} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 07:12:50,299] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 07:12:50,301] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 07:12:50,301] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 07:12:50,300] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 07:12:50,300] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 07:12:50,300] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 07:12:50,304] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 07:12:50,305] ({Thread-62} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:12:50,300] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 07:12:50,300] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 07:12:50,300] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 07:12:50,299] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 07:12:50,312] ({Thread-83} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 07:12:50,299] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 07:12:50,299] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 07:12:50,312] ({Thread-85} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 07:12:50,312] ({Thread-84} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 07:12:50,312] ({Thread-82} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 07:12:50,311] ({Thread-81} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 07:12:50,311] ({Thread-80} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 07:12:50,310] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 07:12:50,310] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 07:12:50,310] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 07:12:50,310] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 07:12:50,310] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 07:12:50,310] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 07:12:50,310] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 07:12:50,309] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 07:12:50,309] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 07:12:50,309] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 07:12:50,309] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 07:12:50,309] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 07:12:50,309] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 07:12:50,309] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 07:12:50,306] ({Thread-62} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 INFO [2020-02-19 07:12:50,306] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 07:12:50,304] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 07:12:50,304] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 07:12:50,303] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 07:12:50,303] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 07:12:50,302] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 07:12:50,302] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 07:12:50,302] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 07:12:50,302] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 WARN [2020-02-19 07:12:50,435] ({Thread-62} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 WARN [2020-02-19 07:12:50,436] ({Thread-62} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 WARN [2020-02-19 07:12:50,438] ({Thread-62} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.PySparkInterpreter
 WARN [2020-02-19 07:12:50,439] ({Thread-62} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.IPySparkInterpreter
 WARN [2020-02-19 07:12:50,440] ({Thread-62} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 07:12:50,443] ({Thread-62} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: spark:shared_process as all the sessions are closed
 INFO [2020-02-19 07:12:50,444] ({Thread-62} ManagedInterpreterGroup.java[close]:108) - Kill RemoteInterpreterProcess
 INFO [2020-02-19 07:12:50,444] ({Thread-62} RemoteInterpreterManagedProcess.java[stop]:220) - Kill interpreter process
ERROR [2020-02-19 07:12:50,723] ({Thread-38} RemoteInterpreterEventPoller.java[run]:257) - Can not get RemoteInterpreterEvent because it is shutdown.
ERROR [2020-02-19 07:12:50,728] ({pool-6-thread-1} AppendOutputRunner.java[run]:68) - Wait for OutputBuffer queue interrupted: null
 WARN [2020-02-19 07:12:53,155] ({Thread-62} RemoteInterpreterManagedProcess.java[stop]:230) - ignore the exception when shutting down
 INFO [2020-02-19 07:12:53,158] ({Thread-62} RemoteInterpreterManagedProcess.java[stop]:238) - Remote process terminated
 INFO [2020-02-19 07:12:53,159] ({Thread-80} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:12:53,159] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 07:12:53,181] ({Exec Default Executor} RemoteInterpreterManagedProcess.java[onProcessFailed]:250) - Interpreter process failed {}
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 WARN [2020-02-19 07:13:18,407] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 07:13:18,563] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 07:13:18,564] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 07:13:18,568] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 07:13:18,576] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 07:13:18,732] ({main} Log.java[initialized]:193) - Logging initialized @2313ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 07:13:19,268] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 07:13:19,447] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 07:13:19,756] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 07:13:19,759] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 07:13:24,632] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 07:13:24,717] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 07:13:24,722] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 07:13:24,738] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-02-19 07:13:26,012] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 07:13:26,112] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 07:13:26,124] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 07:13:26,476] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 07:13:26,479] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 07:13:26,595] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 07:13:26,616] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 07:13:26,627] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 07:13:26,664] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 07:13:26,711] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 07:13:26,748] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 07:13:27,784] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 07:13:27,790] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 07:13:27,805] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 07:13:27,811] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 07:13:27,817] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 07:13:27,824] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 07:13:27,840] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 07:13:27,853] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 07:13:27,859] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 07:13:27,866] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 07:13:27,881] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 07:13:27,888] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 07:13:27,893] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 07:13:27,904] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 07:13:27,912] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 07:13:27,921] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 07:13:27,926] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 07:13:27,938] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 07:13:27,940] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 07:13:28,069] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 07:13:28,071] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 07:13:28,073] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 07:13:28,077] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 07:13:28,079] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 07:13:28,081] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 07:13:28,083] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 07:13:28,084] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 07:13:28,088] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 07:13:28,092] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 07:13:28,093] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 07:13:28,095] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 07:13:28,097] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 07:13:28,100] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 07:13:28,106] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 07:13:28,107] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 07:13:28,110] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 07:13:28,111] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 07:13:28,112] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 07:13:28,114] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 07:13:28,116] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 07:13:28,118] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 07:13:28,181] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 07:13:28,510] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 07:13:28,633] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 07:13:28,828] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 07:13:29,011] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 07:13:29,012] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 07:13:29,014] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 07:13:29,103] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 07:13:29,112] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 07:13:29,146] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 07:13:29,147] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 07:13:29,149] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 07:13:29,152] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 07:13:29,153] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 07:13:29,154] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 07:13:29,155] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 07:13:29,427] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 07:13:29,429] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 07:13:29,432] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 07:13:29,434] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,456] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 07:13:29,458] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,473] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 07:13:29,474] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,485] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 07:13:29,490] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,505] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 07:13:29,506] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,516] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 07:13:29,517] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,524] ({main} Folder.java[addNote]:185) - Add note 2EZZ5HVRW to folder /
 WARN [2020-02-19 07:13:29,525] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,532] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 07:13:29,534] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:13:29,535] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 07:13:29,756] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 8 notebooks took 220ms
 INFO [2020-02-19 07:13:29,757] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 8 indexed in 0s
 INFO [2020-02-19 07:13:29,762] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 07:13:29,764] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 07:13:29,774] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 07:13:33,278] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 07:13:33,358] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@5a6fa56e{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 07:13:33,359] ({main} Server.java[doStart]:407) - Started @16950ms
 INFO [2020-02-19 07:13:33,360] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 07:17:06,708] ({qtp395629617-15} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 07:17:06,910] ({qtp395629617-11} NotebookServer.java[onOpen]:151) - New connection from 172.26.0.1 : 34168
 INFO [2020-02-19 07:17:11,209] ({qtp395629617-14} NotebookServer.java[sendNote]:828) - New operation from 172.26.0.1 : 34168 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 07:17:11,383] ({qtp395629617-14} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 07:17:11,406] ({qtp395629617-14} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:17:11,418] ({qtp395629617-14} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:17:11,420] ({qtp395629617-14} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:17:11,422] ({qtp395629617-14} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:17:11,423] ({qtp395629617-14} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:17:11,424] ({qtp395629617-14} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 07:17:11,457] ({qtp395629617-15} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2EZZ5HVRW
 INFO [2020-02-19 07:17:11,463] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:17:11,464] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:17:11,465] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:17:11,467] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:17:11,469] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:17:11,471] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:17:11,474] ({qtp395629617-15} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-02-19 07:17:18,752] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:17:18,783] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:17:18,787] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:17:18,789] ({pool-2-thread-2} ManagedInterpreterGroup.java[getOrCreateInterpreterProcess]:61) - Create InterpreterProcess for InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:17:18,791] ({pool-2-thread-2} ShellScriptLauncher.java[launch]:48) - Launching Interpreter: spark
 INFO [2020-02-19 07:17:18,804] ({pool-2-thread-2} SparkInterpreterLauncher.java[buildEnvFromProperties]:108) - Run Spark under non-secure mode as no keytab and principal is specified
 INFO [2020-02-19 07:17:18,809] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:115) - Thrift server for callback will start. Port: 35037
 INFO [2020-02-19 07:17:18,828] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:190) - Run interpreter process [/zeppelin/bin/interpreter.sh, -d, /zeppelin/interpreter/spark, -c, 172.26.0.2, -p, 35037, -r, :, -l, /usr/local/local-repo/spark, -g, spark]
 INFO [2020-02-19 07:17:21,854] ({pool-7-thread-1} RemoteInterpreterManagedProcess.java[callback]:123) - RemoteInterpreterServer Registered: CallbackInfo(host:172.26.0.2, port:36579)
 INFO [2020-02-19 07:17:21,905] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 07:17:22,000] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-02-19 07:17:22,004] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-02-19 07:17:22,008] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-02-19 07:17:22,013] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-02-19 07:17:22,019] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 07:17:22,022] ({pool-2-thread-2} RemoteInterpreter.java[call]:142) - Open RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 07:17:22,023] ({pool-2-thread-2} RemoteInterpreter.java[pushAngularObjectRegistryToRemote]:436) - Push local angular object registry from ZeppelinServer to remote interpreter group spark:shared_process
 WARN [2020-02-19 07:17:48,032] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text bankText: org.apache.spark.rdd.RDD[String] = /data/test.txt MapPartitionsRDD[1] at textFile at <console>:25
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, 172.26.0.7, executor 1): java.io.FileNotFoundException: File file:/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 48 elided
Caused by: java.io.FileNotFoundException: File file:/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:17:48,061] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:17:48,093] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:18:39,989] ({qtp395629617-12} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:18:46,957] ({qtp395629617-12} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:18:49,451] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:18:59,373] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:18:59,397] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:18:59,398] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:18:59,716] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:18:59,734] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:18:59,756] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:19:24,897] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:19:35,352] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:19:35,480] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:19:35,499] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:19:35,500] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:19:36,037] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:19:36,053] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:19:36,074] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:04,838] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:04,940] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:04,966] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:04,969] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:21:05,737] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:21:05,757] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:05,776] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:13,916] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:14,009] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:14,027] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:14,028] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:21:14,533] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:21:14,555] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:14,581] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:31,147] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:31,248] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:31,269] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:31,271] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:21:32,945] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
res4: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = ///data/test.txt MapPartitionsRDD[3] at textFile at <console>:34
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7, 172.26.0.6, executor 0): java.io.FileNotFoundException: File file:/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 51 elided
Caused by: java.io.FileNotFoundException: File file:/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:21:32,974] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:32,999] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:55,043] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:55,105] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:55,127] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:21:55,129] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:21:56,759] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
res6: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = /data/test.txt MapPartitionsRDD[5] at textFile at <console>:36
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 11, 172.26.0.6, executor 0): java.io.FileNotFoundException: File file:/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 52 elided
Caused by: java.io.FileNotFoundException: File file:/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:21:56,772] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:21:56,804] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:22:09,281] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:22:09,398] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:22:09,421] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:22:09,423] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:22:11,109] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
res8: Boolean = false
bankText: org.apache.spark.rdd.RDD[String] = /data/test.txt MapPartitionsRDD[7] at textFile at <console>:38
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 4 times, most recent failure: Lost task 0.3 in stage 3.0 (TID 15, 172.26.0.6, executor 0): java.io.FileNotFoundException: File file:/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 53 elided
Caused by: java.io.FileNotFoundException: File file:/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:22:11,127] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:22:11,147] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:22:17,403] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:23:09,868] ({qtp395629617-12} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:23:10,560] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:23:10,581] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:23:10,584] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:23:11,155] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
res10: Boolean = true
<console>:1: error: invalid escape character
val bankText = sc.textFile("\data\test.txt")
                             ^

 INFO [2020-02-19 07:23:11,170] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:23:11,216] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:23:22,650] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:25:36,941] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:25:37,042] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:25:37,068] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:25:37,071] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:25:38,481] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
res11: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = data/test.txt MapPartitionsRDD[9] at textFile at <console>:42
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/zeppelin/data/test.txt
  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)
  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)
  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)
  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:204)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1343)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 55 elided

 INFO [2020-02-19 07:25:38,498] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:25:38,519] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:27:48,399] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 07:27:48,413] ({qtp395629617-15} NotebookServer.java[onClose]:372) - Closed connection to 172.26.0.1 : 34168. (1000) null
 INFO [2020-02-19 07:27:48,417] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@5a6fa56e{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 07:27:48,420] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 07:27:50,008] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 07:27:50,010] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 07:27:50,011] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 07:27:50,011] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 07:27:50,011] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 07:27:50,011] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 07:27:50,011] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 07:27:50,011] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 07:27:50,010] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 07:27:50,010] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 07:27:50,010] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 07:27:50,025] ({Thread-85} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 07:27:50,025] ({Thread-83} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 07:27:50,022] ({Thread-84} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 07:27:50,022] ({Thread-82} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 07:27:50,022] ({Thread-80} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 07:27:50,022] ({Thread-81} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 07:27:50,021] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 07:27:50,020] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 07:27:50,020] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 07:27:50,020] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 07:27:50,020] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 07:27:50,020] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 07:27:50,017] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 07:27:50,016] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 07:27:50,016] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 07:27:50,015] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 07:27:50,015] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 07:27:50,015] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 07:27:50,015] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 07:27:50,015] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 07:27:50,015] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 07:27:50,014] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 07:27:50,014] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 07:27:50,013] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 07:27:50,012] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 07:27:50,012] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 07:27:50,011] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 07:27:50,034] ({Thread-82} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:27:50,033] ({Thread-91} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 07:27:50,033] ({Thread-92} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 07:27:50,026] ({Thread-90} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 07:27:50,026] ({Thread-88} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 07:27:50,026] ({Thread-89} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 07:27:50,026] ({Thread-87} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 07:27:50,025] ({Thread-86} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 07:27:50,052] ({Thread-82} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 WARN [2020-02-19 07:27:50,196] ({Thread-82} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 WARN [2020-02-19 07:27:50,198] ({Thread-82} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 WARN [2020-02-19 07:27:50,199] ({Thread-82} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.PySparkInterpreter
 WARN [2020-02-19 07:27:50,200] ({Thread-82} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.IPySparkInterpreter
 WARN [2020-02-19 07:27:50,201] ({Thread-82} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 07:27:50,203] ({Thread-82} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: spark:shared_process as all the sessions are closed
 INFO [2020-02-19 07:27:50,204] ({Thread-82} ManagedInterpreterGroup.java[close]:108) - Kill RemoteInterpreterProcess
 INFO [2020-02-19 07:27:50,205] ({Thread-82} RemoteInterpreterManagedProcess.java[stop]:220) - Kill interpreter process
ERROR [2020-02-19 07:27:50,756] ({Thread-37} RemoteInterpreterEventPoller.java[run]:257) - Can not get RemoteInterpreterEvent because it is shutdown.
ERROR [2020-02-19 07:27:50,759] ({pool-6-thread-1} AppendOutputRunner.java[run]:68) - Wait for OutputBuffer queue interrupted: null
 WARN [2020-02-19 07:27:52,917] ({Thread-82} RemoteInterpreterManagedProcess.java[stop]:230) - ignore the exception when shutting down
 INFO [2020-02-19 07:27:52,918] ({Thread-82} RemoteInterpreterManagedProcess.java[stop]:238) - Remote process terminated
 INFO [2020-02-19 07:27:52,919] ({Thread-80} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:27:52,920] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 07:27:52,949] ({Exec Default Executor} RemoteInterpreterManagedProcess.java[onProcessFailed]:250) - Interpreter process failed {}
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2020-02-19 07:27:55,934] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
 WARN [2020-02-19 07:28:19,416] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 07:28:19,511] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 07:28:19,513] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 07:28:19,515] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 07:28:19,524] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 07:28:19,636] ({main} Log.java[initialized]:193) - Logging initialized @2377ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 07:28:20,100] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 07:28:20,280] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 07:28:20,512] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 07:28:20,515] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 07:28:25,227] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 07:28:25,342] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 07:28:25,347] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 07:28:25,371] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 600000ms
 INFO [2020-02-19 07:28:26,715] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 07:28:26,789] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 07:28:26,803] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 07:28:27,067] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 07:28:27,079] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 07:28:27,239] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 07:28:27,255] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 07:28:27,271] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 07:28:27,286] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 07:28:27,335] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 07:28:27,393] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 07:28:28,365] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 07:28:28,372] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 07:28:28,377] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 07:28:28,383] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 07:28:28,390] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 07:28:28,396] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 07:28:28,405] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 07:28:28,432] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 07:28:28,442] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 07:28:28,457] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 07:28:28,473] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 07:28:28,485] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 07:28:28,499] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 07:28:28,507] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 07:28:28,519] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 07:28:28,535] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 07:28:28,544] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 07:28:28,559] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 07:28:28,561] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 07:28:28,649] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 07:28:28,652] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 07:28:28,655] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 07:28:28,658] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 07:28:28,660] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 07:28:28,662] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 07:28:28,664] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 07:28:28,666] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 07:28:28,669] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 07:28:28,671] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 07:28:28,672] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 07:28:28,674] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 07:28:28,676] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 07:28:28,680] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 07:28:28,686] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 07:28:28,688] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 07:28:28,690] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 07:28:28,693] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 07:28:28,694] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 07:28:28,695] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 07:28:28,697] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 07:28:28,698] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 07:28:28,747] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 07:28:29,043] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 07:28:29,137] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 07:28:29,349] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 07:28:29,548] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 07:28:29,549] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 07:28:29,552] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 07:28:29,642] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 07:28:29,650] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 07:28:29,676] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 07:28:29,679] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 07:28:29,680] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 07:28:29,683] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 07:28:29,684] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 07:28:29,686] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 07:28:29,687] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 07:28:29,966] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 07:28:29,967] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 07:28:29,968] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 07:28:29,970] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:29,994] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 07:28:29,995] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,010] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 07:28:30,012] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,022] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 07:28:30,024] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,038] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 07:28:30,039] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,047] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 07:28:30,049] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,056] ({main} Folder.java[addNote]:185) - Add note 2EZZ5HVRW to folder /
 WARN [2020-02-19 07:28:30,057] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,063] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 07:28:30,064] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 07:28:30,065] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 07:28:30,296] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 8 notebooks took 229ms
 INFO [2020-02-19 07:28:30,297] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 8 indexed in 0s
 INFO [2020-02-19 07:28:30,300] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 07:28:30,304] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 07:28:30,311] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 07:28:32,962] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 07:28:33,002] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@5a6fa56e{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 07:28:33,003] ({main} Server.java[doStart]:407) - Started @15775ms
 INFO [2020-02-19 07:28:33,004] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 07:28:48,543] ({qtp395629617-10} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 07:28:48,859] ({qtp395629617-16} NotebookServer.java[onOpen]:151) - New connection from 172.27.0.1 : 52832
 INFO [2020-02-19 07:28:49,079] ({qtp395629617-16} NotebookServer.java[sendNote]:828) - New operation from 172.27.0.1 : 52832 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 07:28:49,228] ({qtp395629617-16} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 07:28:49,237] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:28:49,239] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:28:49,240] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:28:49,242] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:28:49,243] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 07:28:49,244] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 07:28:49,271] ({qtp395629617-15} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2EZZ5HVRW
 INFO [2020-02-19 07:28:49,275] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:28:49,276] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:28:49,277] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:28:49,278] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:28:49,279] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:28:49,280] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 07:28:49,282] ({qtp395629617-15} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-02-19 07:29:04,780] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:29:04,844] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:29:04,886] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:29:04,890] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:29:04,891] ({pool-2-thread-2} ManagedInterpreterGroup.java[getOrCreateInterpreterProcess]:61) - Create InterpreterProcess for InterpreterGroup: spark:shared_process
 INFO [2020-02-19 07:29:04,893] ({pool-2-thread-2} ShellScriptLauncher.java[launch]:48) - Launching Interpreter: spark
 INFO [2020-02-19 07:29:04,919] ({pool-2-thread-2} SparkInterpreterLauncher.java[buildEnvFromProperties]:108) - Run Spark under non-secure mode as no keytab and principal is specified
 INFO [2020-02-19 07:29:04,923] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:115) - Thrift server for callback will start. Port: 36979
 INFO [2020-02-19 07:29:04,938] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:190) - Run interpreter process [/zeppelin/bin/interpreter.sh, -d, /zeppelin/interpreter/spark, -c, 172.27.0.3, -p, 36979, -r, :, -l, /usr/local/local-repo/spark, -g, spark]
 INFO [2020-02-19 07:29:08,678] ({pool-7-thread-1} RemoteInterpreterManagedProcess.java[callback]:123) - RemoteInterpreterServer Registered: CallbackInfo(host:172.27.0.3, port:39881)
 INFO [2020-02-19 07:29:08,764] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 07:29:08,926] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-02-19 07:29:08,930] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-02-19 07:29:08,934] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-02-19 07:29:08,940] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-02-19 07:29:08,947] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 07:29:08,951] ({pool-2-thread-2} RemoteInterpreter.java[call]:142) - Open RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 07:29:08,952] ({pool-2-thread-2} RemoteInterpreter.java[pushAngularObjectRegistryToRemote]:436) - Push local angular object registry from ZeppelinServer to remote interpreter group spark:shared_process
 INFO [2020-02-19 07:29:28,470] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:29:28,532] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:29:28,567] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:29:41,808] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:29:41,904] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:29:41,927] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:29:41,929] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:29:42,442] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:29:42,459] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:29:42,481] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:32:01,674] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:32:01,797] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:32:01,821] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:32:01,822] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:32:02,417] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
res2: Boolean = true
<console>:29: error: not found: value Source
         val src = Source.fromFile("data/test.txt")
                   ^

 INFO [2020-02-19 07:32:02,432] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:32:02,463] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:33:07,468] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:33:07,577] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:33:07,602] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:33:07,604] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:33:09,169] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:33:09,181] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:33:09,203] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:33:43,110] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:33:47,125] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:33:52,950] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:34:29,389] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:34:40,662] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:34:40,688] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:34:40,690] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:34:46,565] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res4: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = data/test.txt MapPartitionsRDD[1] at textFile at <console>:36
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, 172.27.0.6, executor 0): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 51 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:34:46,582] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:34:46,607] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:36:44,964] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:36:45,062] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:36:45,086] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:36:45,087] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:36:46,499] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:36:46,515] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:36:46,558] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:37:17,793] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:37:17,902] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:37:17,925] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:37:17,927] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:37:18,858] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:37:18,866] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:37:18,893] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:38:12,155] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:38:12,889] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:38:12,908] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:38:12,910] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:38:14,147] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:38:14,161] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:38:14,186] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:39:43,876] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:39:43,917] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:39:43,920] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:39:45,219] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:39:45,228] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:39:45,247] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:40:13,559] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:13,641] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:13,657] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:40:13,659] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:40:14,776] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:40:14,787] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:14,806] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:40:27,081] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:27,189] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:27,213] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:40:27,216] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:40:29,407] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res14: Boolean = true
res15: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = data/test.txt MapPartitionsRDD[3] at textFile at <console>:54
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 57 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:40:29,428] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:29,462] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:40:49,171] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:49,270] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:49,291] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:40:49,292] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:40:51,440] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res17: Boolean = true
res18: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = /data/test.txt MapPartitionsRDD[5] at textFile at <console>:57
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/data/test.txt
  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)
  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)
  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)
  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:204)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1343)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 58 elided

 INFO [2020-02-19 07:40:51,497] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:40:51,520] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:41:21,432] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:41:21,541] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:41:21,566] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:41:21,568] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:41:23,552] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res20: Boolean = true
res21: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = /zeppelin/data/test.txt MapPartitionsRDD[7] at textFile at <console>:60
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 11, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 59 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:41:23,574] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:41:23,596] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:41:36,213] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:41:36,340] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:41:36,367] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:41:36,368] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:41:38,341] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res23: Boolean = true
res24: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = ///zeppelin/data/test.txt MapPartitionsRDD[9] at textFile at <console>:63
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 4 times, most recent failure: Lost task 0.3 in stage 3.0 (TID 15, 172.27.0.6, executor 0): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 60 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:41:38,359] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:41:38,380] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:43:03,852] ({qtp395629617-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:43:03,946] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:43:03,975] ({pool-2-thread-16} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:43:03,981] ({pool-2-thread-16} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:43:06,003] ({pool-2-thread-16} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res26: Boolean = true
res27: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = zeppelin/data/test.txt MapPartitionsRDD[11] at textFile at <console>:66
org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: file:/zeppelin/zeppelin/data/test.txt
  at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:287)
  at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:229)
  at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:315)
  at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:204)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
  at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:49)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:253)
  at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:251)
  at scala.Option.getOrElse(Option.scala:121)
  at org.apache.spark.rdd.RDD.partitions(RDD.scala:251)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1343)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 61 elided

 INFO [2020-02-19 07:43:06,008] ({pool-2-thread-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:43:06,024] ({pool-2-thread-16} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:43:27,938] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:43:27,983] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:43:28,008] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:43:28,009] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:43:30,013] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res29: Boolean = true
res30: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = data/test.txt MapPartitionsRDD[13] at textFile at <console>:69
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 4 times, most recent failure: Lost task 0.3 in stage 4.0 (TID 19, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 62 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:43:30,019] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:43:30,047] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:44:01,776] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:44:01,831] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:44:01,852] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:44:01,853] ({pool-2-thread-10} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:44:03,751] ({pool-2-thread-10} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res32: Boolean = true
res33: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = data/test.txt MapPartitionsRDD[15] at textFile at <console>:72
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 4 times, most recent failure: Lost task 0.3 in stage 5.0 (TID 23, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 63 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:44:03,768] ({pool-2-thread-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:44:03,794] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:44:09,621] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:44:09,647] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:44:09,649] ({pool-2-thread-6} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:44:11,626] ({pool-2-thread-6} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res35: Boolean = true
res36: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = data/test.txt MapPartitionsRDD[17] at textFile at <console>:75
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 6.0 failed 4 times, most recent failure: Lost task 0.3 in stage 6.0 (TID 27, 172.27.0.6, executor 0): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 64 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:44:11,635] ({pool-2-thread-6} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:44:11,655] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:46:10,009] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:46:10,055] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:46:10,071] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:46:10,072] ({pool-2-thread-11} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:46:12,072] ({pool-2-thread-11} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res38: Boolean = true
res39: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = file:/zeppelin/data/test.txt MapPartitionsRDD[19] at textFile at <console>:78
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 7.0 failed 4 times, most recent failure: Lost task 0.3 in stage 7.0 (TID 31, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 65 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:46:12,081] ({pool-2-thread-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:46:12,100] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:46:31,959] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:46:32,011] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:46:32,039] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:46:32,042] ({pool-2-thread-4} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:46:34,233] ({pool-2-thread-4} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
res41: Boolean = true
res42: Boolean = true
currentDirectory: String = /zeppelin
bankText: org.apache.spark.rdd.RDD[String] = file:///zeppelin/data/test.txt MapPartitionsRDD[21] at textFile at <console>:81
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 4 times, most recent failure: Lost task 0.3 in stage 8.0 (TID 35, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 66 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:46:34,246] ({pool-2-thread-4} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:46:34,378] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:48:38,759] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:48:38,802] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:48:38,832] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:48:38,833] ({pool-2-thread-12} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:48:40,004] ({pool-2-thread-12} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:48:40,015] ({pool-2-thread-12} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:48:40,031] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:51:01,092] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:51:01,144] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:51:01,173] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:51:01,176] ({pool-2-thread-7} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:51:03,697] ({pool-2-thread-7} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:51:03,703] ({pool-2-thread-7} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:51:03,718] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:51:25,543] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:51:25,588] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:51:25,622] ({pool-2-thread-13} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:51:25,630] ({pool-2-thread-13} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:51:32,783] ({pool-2-thread-13} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:51:32,803] ({pool-2-thread-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:51:32,823] ({pool-2-thread-13} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:52:08,973] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:52:09,034] ({qtp395629617-13} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:52:09,054] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:52:09,055] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:52:13,595] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res51: Boolean = true
res52: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
<console>:101: error: value saveAsTextFile is not a member of org.apache.spark.sql.DataFrame
       someDF.saveAsTextFile("prueba.txt")
              ^

 INFO [2020-02-19 07:52:13,608] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:52:13,645] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:54:22,031] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:54:22,071] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:54:22,101] ({pool-2-thread-14} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:54:22,103] ({pool-2-thread-14} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:54:34,171] ({pool-2-thread-14} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:54:34,207] ({pool-2-thread-14} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:54:34,222] ({pool-2-thread-14} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:55:00,958] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:55:00,997] ({qtp395629617-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:55:01,020] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:55:01,023] ({pool-2-thread-8} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:55:06,969] ({pool-2-thread-8} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res57: Boolean = true
res58: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/zeppelin/prueba.txt already exists
  at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
  at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:287)
  at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)
  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)
  ... 78 elided

 INFO [2020-02-19 07:55:07,307] ({pool-2-thread-8} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:55:07,374] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:55:45,058] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:55:45,121] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:55:45,150] ({pool-2-thread-15} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:55:45,152] ({pool-2-thread-15} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 07:55:49,890] ({pool-2-thread-15} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-065917_1853343063 is finished successfully, status: FINISHED
 INFO [2020-02-19 07:55:50,106] ({pool-2-thread-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:55:50,124] ({pool-2-thread-15} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:56:24,366] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:56:24,391] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:56:24,408] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:56:24,410] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:56:29,689] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res64: Boolean = true
res65: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
res67: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = file:///zeppelin/prueba3.txt MapPartitionsRDD[43] at textFile at <console>:120
java.lang.UnsupportedOperationException: empty collection
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1380)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 82 elided

 INFO [2020-02-19 07:56:29,757] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:56:29,778] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:57:38,758] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:57:38,832] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:57:38,865] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:57:38,866] ({pool-2-thread-9} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:57:42,174] ({pool-2-thread-9} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res69: Boolean = true
res70: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/zeppelin/prueba3.txt already exists
  at org.apache.hadoop.mapred.FileOutputFormat.checkOutputSpecs(FileOutputFormat.java:131)
  at org.apache.spark.internal.io.HadoopMapRedWriteConfigUtil.assertConf(SparkHadoopWriter.scala:287)
  at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:71)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopDataset(PairRDDFunctions.scala:1094)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1067)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1032)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1032)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply$mcV$sp(PairRDDFunctions.scala:958)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
  at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$1.apply(PairRDDFunctions.scala:958)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:957)
  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply$mcV$sp(RDD.scala:1499)
  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
  at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1.apply(RDD.scala:1478)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1478)
  ... 84 elided

 INFO [2020-02-19 07:57:42,205] ({pool-2-thread-9} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:57:42,224] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:58:13,500] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:58:13,574] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:58:13,597] ({pool-2-thread-16} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:58:13,600] ({pool-2-thread-16} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:58:18,038] ({pool-2-thread-16} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res72: Boolean = true
res73: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
res74: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = file:///zeppelin/data/test.txt MapPartitionsRDD[50] at textFile at <console>:130
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12.0 (TID 48, 172.27.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 86 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:58:18,159] ({pool-2-thread-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:58:18,190] ({pool-2-thread-16} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:59:53,104] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:59:53,173] ({qtp395629617-11} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:59:53,230] ({pool-2-thread-17} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 07:59:53,232] ({pool-2-thread-17} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 07:59:56,804] ({pool-2-thread-17} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res76: Boolean = false
res77: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
res78: Boolean = true
bankText: org.apache.spark.rdd.RDD[String] = file:///zeppelin/data/test.txt MapPartitionsRDD[52] at textFile at <console>:135
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 13.0 failed 4 times, most recent failure: Lost task 0.3 in stage 13.0 (TID 52, 172.27.0.6, executor 0): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 88 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 07:59:56,881] ({pool-2-thread-17} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 07:59:56,911] ({pool-2-thread-17} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 08:01:43,802] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 08:01:43,930] ({qtp395629617-10} NotebookServer.java[onClose]:372) - Closed connection to 172.27.0.1 : 52832. (1000) null
 INFO [2020-02-19 08:01:43,948] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@5a6fa56e{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 08:01:43,950] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 08:01:47,156] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 08:01:47,166] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 08:01:47,167] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 08:01:47,166] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 08:01:47,167] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 08:01:47,174] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 08:01:47,174] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 08:01:47,176] ({Thread-81} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 08:01:47,176] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 08:01:47,176] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 08:01:47,179] ({Thread-84} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 08:01:47,175] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 08:01:47,182] ({Thread-91} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 08:01:47,180] ({Thread-82} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 08:01:47,182] ({Thread-89} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 08:01:47,182] ({Thread-87} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 08:01:47,181] ({Thread-88} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 08:01:47,181] ({Thread-86} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 08:01:47,179] ({Thread-85} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 08:01:47,179] ({Thread-83} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 08:01:47,177] ({Thread-80} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 08:01:47,198] ({Thread-113} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 08:01:47,197] ({Thread-114} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 08:01:47,195] ({Thread-112} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 08:01:47,194] ({Thread-111} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 08:01:47,193] ({Thread-110} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 08:01:47,191] ({Thread-108} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 08:01:47,191] ({Thread-109} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 08:01:47,188] ({Thread-107} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 08:01:47,188] ({Thread-106} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 08:01:47,188] ({Thread-103} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 08:01:47,187] ({Thread-101} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 08:01:47,187] ({Thread-105} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 08:01:47,186] ({Thread-104} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 08:01:47,186] ({Thread-102} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 08:01:47,185] ({Thread-96} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 08:01:47,185] ({Thread-100} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 08:01:47,185] ({Thread-92} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 08:01:47,185] ({Thread-99} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 08:01:47,185] ({Thread-90} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 08:01:47,185] ({Thread-98} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 08:01:47,185] ({Thread-93} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 08:01:47,185] ({Thread-94} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 08:01:47,184] ({Thread-97} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 08:01:47,184] ({Thread-95} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 08:01:47,202] ({Thread-109} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 08:01:47,213] ({Thread-109} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 WARN [2020-02-19 08:01:47,495] ({Thread-109} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 WARN [2020-02-19 08:01:47,497] ({Thread-109} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 WARN [2020-02-19 08:01:47,499] ({Thread-109} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.PySparkInterpreter
 WARN [2020-02-19 08:01:47,500] ({Thread-109} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.IPySparkInterpreter
 WARN [2020-02-19 08:01:47,501] ({Thread-109} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 08:01:47,504] ({Thread-109} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: spark:shared_process as all the sessions are closed
 INFO [2020-02-19 08:01:47,504] ({Thread-109} ManagedInterpreterGroup.java[close]:108) - Kill RemoteInterpreterProcess
 INFO [2020-02-19 08:01:47,505] ({Thread-109} RemoteInterpreterManagedProcess.java[stop]:220) - Kill interpreter process
ERROR [2020-02-19 08:01:48,092] ({Thread-37} RemoteInterpreterEventPoller.java[run]:257) - Can not get RemoteInterpreterEvent because it is shutdown.
ERROR [2020-02-19 08:01:48,094] ({pool-6-thread-1} AppendOutputRunner.java[run]:68) - Wait for OutputBuffer queue interrupted: null
 WARN [2020-02-19 08:01:51,090] ({Thread-109} RemoteInterpreterManagedProcess.java[stop]:230) - ignore the exception when shutting down
 INFO [2020-02-19 08:01:51,094] ({Thread-109} RemoteInterpreterManagedProcess.java[stop]:238) - Remote process terminated
 INFO [2020-02-19 08:01:51,095] ({Thread-98} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 08:01:51,096] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 08:01:51,112] ({Exec Default Executor} RemoteInterpreterManagedProcess.java[onProcessFailed]:250) - Interpreter process failed {}
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 WARN [2020-02-19 08:07:49,486] ({main} ZeppelinConfiguration.java[create]:117) - Failed to load configuration, proceeding with a default
 INFO [2020-02-19 08:07:49,633] ({main} ZeppelinConfiguration.java[create]:129) - Server Host: 0.0.0.0
 INFO [2020-02-19 08:07:49,636] ({main} ZeppelinConfiguration.java[create]:131) - Server Port: 8080
 INFO [2020-02-19 08:07:49,641] ({main} ZeppelinConfiguration.java[create]:135) - Context Path: /
 INFO [2020-02-19 08:07:49,661] ({main} ZeppelinConfiguration.java[create]:136) - Zeppelin Version: 0.8.2
 INFO [2020-02-19 08:07:49,847] ({main} Log.java[initialized]:193) - Logging initialized @3929ms to org.eclipse.jetty.util.log.Slf4jLog
 WARN [2020-02-19 08:07:50,555] ({main} ServerConnector.java[setSoLingerTime]:458) - Ignoring deprecated socket close linger time
 INFO [2020-02-19 08:07:50,760] ({main} ZeppelinServer.java[setupWebAppContext]:413) - ZeppelinServer Webapp path: /zeppelin/webapps
 INFO [2020-02-19 08:07:51,120] ({main} ZeppelinServer.java[main]:239) - Starting zeppelin server
 INFO [2020-02-19 08:07:51,126] ({main} Server.java[doStart]:370) - jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_222-8u222-b10-1ubuntu1~16.04.1-b10
 INFO [2020-02-19 08:07:56,600] ({main} StandardDescriptorProcessor.java[visitServlet]:283) - NO JSP Support for /, did not find org.eclipse.jetty.jsp.JettyJspServlet
 INFO [2020-02-19 08:07:56,728] ({main} DefaultSessionIdManager.java[doStart]:365) - DefaultSessionIdManager workerName=node0
 INFO [2020-02-19 08:07:56,729] ({main} DefaultSessionIdManager.java[doStart]:370) - No SessionScavenger set, using defaults
 INFO [2020-02-19 08:07:56,751] ({main} HouseKeeper.java[startScavenging]:149) - node0 Scavenging every 660000ms
 INFO [2020-02-19 08:07:57,651] ({main} SchedulerFactory.java[<init>]:59) - Scheduler Thread Pool Size: 100
 WARN [2020-02-19 08:07:57,688] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 WARN [2020-02-19 08:07:57,692] ({main} ZeppelinConfiguration.java[getConfigFSDir]:527) - zeppelin.config.fs.dir is not specified, fall back to local conf directory zeppelin.conf.dir
 INFO [2020-02-19 08:07:57,865] ({main} InterpreterSettingManager.java[<init>]:165) - Using RecoveryStorage: org.apache.zeppelin.interpreter.recovery.NullRecoveryStorage
 INFO [2020-02-19 08:07:57,868] ({main} InterpreterSettingManager.java[<init>]:169) - Using LifecycleManager: org.apache.zeppelin.interpreter.lifecycle.NullLifecycleManager
 INFO [2020-02-19 08:07:57,925] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sh
 INFO [2020-02-19 08:07:57,938] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: hbase
 INFO [2020-02-19 08:07:57,948] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: lens
 INFO [2020-02-19 08:07:57,956] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: angular
 WARN [2020-02-19 08:07:57,979] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/${interpreter.name}
 INFO [2020-02-19 08:07:57,992] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: livy
 WARN [2020-02-19 08:07:58,414] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/scio
 INFO [2020-02-19 08:07:58,420] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: file
 INFO [2020-02-19 08:07:58,426] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: md
 INFO [2020-02-19 08:07:58,431] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: groovy
 INFO [2020-02-19 08:07:58,439] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: kylin
 INFO [2020-02-19 08:07:58,448] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: elasticsearch
 INFO [2020-02-19 08:07:58,456] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: cassandra
 INFO [2020-02-19 08:07:58,464] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: alluxio
 INFO [2020-02-19 08:07:58,473] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: flink
 INFO [2020-02-19 08:07:58,479] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: python
 INFO [2020-02-19 08:07:58,495] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: spark
 INFO [2020-02-19 08:07:58,504] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: pig
 INFO [2020-02-19 08:07:58,513] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: jdbc
 INFO [2020-02-19 08:07:58,531] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: ignite
 INFO [2020-02-19 08:07:58,547] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: sap
 INFO [2020-02-19 08:07:58,553] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: bigquery
 WARN [2020-02-19 08:07:58,562] ({main} InterpreterSettingManager.java[init]:331) - No interpreter-setting.json found in /zeppelin/interpreter/lib
 INFO [2020-02-19 08:07:58,579] ({main} InterpreterSettingManager.java[registerInterpreterSetting]:425) - Register InterpreterSettingTemplate: neo4j
 INFO [2020-02-19 08:07:58,581] ({main} LocalConfigStorage.java[loadInterpreterSettings]:63) - Load Interpreter Setting from file: /zeppelin/conf/interpreter.json
 INFO [2020-02-19 08:07:58,734] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting ignite from interpreter.json
 INFO [2020-02-19 08:07:58,749] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting python from interpreter.json
 INFO [2020-02-19 08:07:58,751] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sap from interpreter.json
 INFO [2020-02-19 08:07:58,754] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting jdbc from interpreter.json
 INFO [2020-02-19 08:07:58,755] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting lens from interpreter.json
 INFO [2020-02-19 08:07:58,764] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting pig from interpreter.json
 INFO [2020-02-19 08:07:58,767] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting flink from interpreter.json
 INFO [2020-02-19 08:07:58,768] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting angular from interpreter.json
 INFO [2020-02-19 08:07:58,770] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting livy from interpreter.json
 INFO [2020-02-19 08:07:58,774] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting neo4j from interpreter.json
 INFO [2020-02-19 08:07:58,775] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting file from interpreter.json
 INFO [2020-02-19 08:07:58,776] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting groovy from interpreter.json
 INFO [2020-02-19 08:07:58,778] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting elasticsearch from interpreter.json
 INFO [2020-02-19 08:07:58,784] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting redshift from interpreter.json
 INFO [2020-02-19 08:07:58,787] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting cassandra from interpreter.json
 INFO [2020-02-19 08:07:58,789] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting sh from interpreter.json
 INFO [2020-02-19 08:07:58,791] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting spark from interpreter.json
 INFO [2020-02-19 08:07:58,793] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting md from interpreter.json
 INFO [2020-02-19 08:07:58,794] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting alluxio from interpreter.json
 INFO [2020-02-19 08:07:58,795] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting bigquery from interpreter.json
 INFO [2020-02-19 08:07:58,796] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting hbase from interpreter.json
 INFO [2020-02-19 08:07:58,798] ({main} InterpreterSettingManager.java[loadFromFile]:279) - Create Interpreter Setting kylin from interpreter.json
 INFO [2020-02-19 08:07:58,879] ({main} LocalConfigStorage.java[save]:53) - Save Interpreter Setting to /zeppelin/conf/interpreter.json
 INFO [2020-02-19 08:07:59,293] ({main} VfsLog.java[info]:138) - Using "/tmp/vfs_cache" as temporary files store.
 INFO [2020-02-19 08:07:59,471] ({main} GitNotebookRepo.java[<init>]:64) - Opening a git repo at '/zeppelin/notebook'
 INFO [2020-02-19 08:07:59,729] ({main} NotebookRepoSync.java[<init>]:77) - Instantiate NotebookRepo: org.apache.zeppelin.notebook.repo.GitNotebookRepo
 WARN [2020-02-19 08:07:59,961] ({main} NotebookAuthorization.java[getInstance]:86) - Notebook authorization module was called without initialization, initializing with default configuration
 WARN [2020-02-19 08:07:59,963] ({main} LocalConfigStorage.java[loadNotebookAuthorization]:77) - NotebookAuthorization file /zeppelin/conf/notebook-authorization.json is not existed
 INFO [2020-02-19 08:07:59,965] ({main} Credentials.java[loadFromFile]:121) - /zeppelin/conf/credentials.json
 INFO [2020-02-19 08:08:00,089] ({main} StdSchedulerFactory.java[instantiate]:1184) - Using default implementation for ThreadExecutor
 INFO [2020-02-19 08:08:00,117] ({main} SimpleThreadPool.java[initialize]:268) - Job execution threads will use class loader of thread: main
 INFO [2020-02-19 08:08:00,179] ({main} SchedulerSignalerImpl.java[<init>]:61) - Initialized Scheduler Signaller of type: class org.quartz.core.SchedulerSignalerImpl
 INFO [2020-02-19 08:08:00,196] ({main} QuartzScheduler.java[<init>]:240) - Quartz Scheduler v.2.2.1 created.
 INFO [2020-02-19 08:08:00,200] ({main} RAMJobStore.java[initialize]:155) - RAMJobStore initialized.
 INFO [2020-02-19 08:08:00,205] ({main} QuartzScheduler.java[initialize]:305) - Scheduler meta-data: Quartz Scheduler (v2.2.1) 'DefaultQuartzScheduler' with instanceId 'NON_CLUSTERED'
  Scheduler class: 'org.quartz.core.QuartzScheduler' - running locally.
  NOT STARTED.
  Currently in standby mode.
  Number of jobs executed: 0
  Using thread pool 'org.quartz.simpl.SimpleThreadPool' - with 10 threads.
  Using job-store 'org.quartz.simpl.RAMJobStore' - which does not support persistence. and is not clustered.

 INFO [2020-02-19 08:08:00,206] ({main} StdSchedulerFactory.java[instantiate]:1339) - Quartz scheduler 'DefaultQuartzScheduler' initialized from default resource file in Quartz package: 'quartz.properties'
 INFO [2020-02-19 08:08:00,207] ({main} StdSchedulerFactory.java[instantiate]:1343) - Quartz scheduler version: 2.2.1
 INFO [2020-02-19 08:08:00,208] ({main} QuartzScheduler.java[start]:575) - Scheduler DefaultQuartzScheduler_$_NON_CLUSTERED started.
 INFO [2020-02-19 08:08:00,641] ({main} FolderView.java[createFolder]:107) - Create folder /
 INFO [2020-02-19 08:08:00,642] ({main} Folder.java[setParent]:169) - Set parent of / to /
 INFO [2020-02-19 08:08:00,643] ({main} Folder.java[addNote]:185) - Add note 2EXBGWKU1 to folder /
 WARN [2020-02-19 08:08:00,646] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,719] ({main} Folder.java[addNote]:185) - Add note 2EXQEGYMG to folder /
 WARN [2020-02-19 08:08:00,721] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,744] ({main} Folder.java[addNote]:185) - Add note 2EXQP4H7Q to folder /
 WARN [2020-02-19 08:08:00,753] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,765] ({main} Folder.java[addNote]:185) - Add note 2EXSBN97B to folder /
 WARN [2020-02-19 08:08:00,771] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,790] ({main} Folder.java[addNote]:185) - Add note 2EXW4GMRD to folder /
 WARN [2020-02-19 08:08:00,791] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,798] ({main} Folder.java[addNote]:185) - Add note 2EZ5YG7UK to folder /
 WARN [2020-02-19 08:08:00,803] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,819] ({main} Folder.java[addNote]:185) - Add note 2EZZ5HVRW to folder /
 WARN [2020-02-19 08:08:00,824] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,832] ({main} Folder.java[addNote]:185) - Add note 2F1BPEKNX to folder /
 WARN [2020-02-19 08:08:00,843] ({main} Notebook.java[refreshCron]:981) - execution of the cron job is skipped cron is not enabled from Zeppelin server
 INFO [2020-02-19 08:08:00,844] ({main} Notebook.java[<init>]:127) - Notebook indexing started...
 INFO [2020-02-19 08:08:01,187] ({main} LuceneSearch.java[addIndexDocs]:305) - Indexing 8 notebooks took 342ms
 INFO [2020-02-19 08:08:01,193] ({main} Notebook.java[<init>]:129) - Notebook indexing finished: 8 indexed in 0s
 INFO [2020-02-19 08:08:01,197] ({main} Helium.java[loadConf]:103) - Add helium local registry /zeppelin/helium
 INFO [2020-02-19 08:08:01,213] ({main} Helium.java[loadConf]:100) - Add helium online registry https://s3.amazonaws.com/helium-package/helium.json
 WARN [2020-02-19 08:08:01,254] ({main} Helium.java[loadConf]:111) - /zeppelin/conf/helium.json does not exists
 INFO [2020-02-19 08:08:04,461] ({main} ContextHandler.java[doStart]:855) - Started o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,file:///zeppelin/webapps/webapp/,AVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 08:08:04,556] ({main} AbstractConnector.java[doStart]:292) - Started ServerConnector@fc807c1{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 08:08:04,558] ({main} Server.java[doStart]:407) - Started @18660ms
 INFO [2020-02-19 08:08:04,559] ({main} ZeppelinServer.java[main]:249) - Done, zeppelin server started
 WARN [2020-02-19 08:08:21,688] ({qtp395629617-11} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 08:08:21,849] ({qtp395629617-16} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 56216
 INFO [2020-02-19 08:08:24,480] ({qtp395629617-16} NotebookServer.java[sendNote]:828) - New operation from 172.30.0.1 : 56216 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 08:08:24,686] ({qtp395629617-16} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 08:08:24,701] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:08:24,714] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:08:24,719] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:08:24,721] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:08:24,723] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:08:24,726] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 08:08:24,778] ({qtp395629617-15} InterpreterSetting.java[getOrCreateInterpreterGroup]:419) - Create InterpreterGroup with groupId: spark:shared_process for user: anonymous and note: 2EZZ5HVRW
 INFO [2020-02-19 08:08:24,783] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 08:08:24,786] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkSqlInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 08:08:24,788] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.DepInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 08:08:24,789] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.PySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 08:08:24,790] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.IPySparkInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 08:08:24,791] ({qtp395629617-15} InterpreterSetting.java[createInterpreters]:689) - Interpreter org.apache.zeppelin.spark.SparkRInterpreter created for user: anonymous, sessionId: shared_session
 INFO [2020-02-19 08:08:24,793] ({qtp395629617-15} ManagedInterpreterGroup.java[getOrCreateSession]:158) - Create Session: shared_session in InterpreterGroup: spark:shared_process for user: anonymous
 INFO [2020-02-19 08:08:47,865] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 08:08:47,907] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 08:08:47,910] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 INFO [2020-02-19 08:08:47,911] ({pool-2-thread-2} ManagedInterpreterGroup.java[getOrCreateInterpreterProcess]:61) - Create InterpreterProcess for InterpreterGroup: spark:shared_process
 INFO [2020-02-19 08:08:47,913] ({pool-2-thread-2} ShellScriptLauncher.java[launch]:48) - Launching Interpreter: spark
 INFO [2020-02-19 08:08:47,941] ({pool-2-thread-2} SparkInterpreterLauncher.java[buildEnvFromProperties]:108) - Run Spark under non-secure mode as no keytab and principal is specified
 INFO [2020-02-19 08:08:47,948] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:115) - Thrift server for callback will start. Port: 43571
 INFO [2020-02-19 08:08:47,961] ({pool-2-thread-2} RemoteInterpreterManagedProcess.java[start]:190) - Run interpreter process [/zeppelin/bin/interpreter.sh, -d, /zeppelin/interpreter/spark, -c, 172.30.0.3, -p, 43571, -r, :, -l, /usr/local/local-repo/spark, -g, spark]
 INFO [2020-02-19 08:08:52,415] ({pool-7-thread-1} RemoteInterpreterManagedProcess.java[callback]:123) - RemoteInterpreterServer Registered: CallbackInfo(host:172.30.0.3, port:43065)
 INFO [2020-02-19 08:08:52,614] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 08:08:52,932] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-02-19 08:08:52,937] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-02-19 08:08:52,943] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-02-19 08:08:52,954] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.IPySparkInterpreter
 INFO [2020-02-19 08:08:52,967] ({pool-2-thread-2} RemoteInterpreter.java[call]:168) - Create RemoteInterpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 08:08:52,971] ({pool-2-thread-2} RemoteInterpreter.java[call]:142) - Open RemoteInterpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-02-19 08:08:52,973] ({pool-2-thread-2} RemoteInterpreter.java[pushAngularObjectRegistryToRemote]:436) - Push local angular object registry from ZeppelinServer to remote interpreter group spark:shared_process
 WARN [2020-02-19 08:09:28,074] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res0: Boolean = false
res1: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
res2: Boolean = false
bankText: org.apache.spark.rdd.RDD[String] = file:///zeppelin/data/test.txt MapPartitionsRDD[1] at textFile at <console>:30
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 3, 172.30.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 49 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 08:09:28,104] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 08:09:28,132] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 08:10:08,541] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 08:10:33,475] ({qtp395629617-10} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 08:10:33,494] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:114) - Job 20200219-065917_1853343063 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 08:10:33,497] ({pool-2-thread-2} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-065917_1853343063, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 08:10:38,845] ({pool-2-thread-2} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-065917_1853343063 is finished, status: ERROR, exception: null, result: %text import java.nio.file.{Paths, Files}
import scala.io.Source
import spark.implicits._
res4: Boolean = true
res5: Boolean = true
currentDirectory: String = /zeppelin
someDF: org.apache.spark.sql.DataFrame = [number: int, word: string]
res6: Boolean = false
bankText: org.apache.spark.rdd.RDD[String] = file:///zeppelin/data/test.txt MapPartitionsRDD[3] at textFile at <console>:35
org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7, 172.30.0.7, executor 1): java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
	at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
	at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
	at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
	at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
	at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
	at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
	at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
	at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
  at scala.Option.foreach(Option.scala:257)
  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
  at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
  at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
  at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
  at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
  at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1364)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.take(RDD.scala:1337)
  at org.apache.spark.rdd.RDD$$anonfun$first$1.apply(RDD.scala:1378)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
  at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
  at org.apache.spark.rdd.RDD.first(RDD.scala:1377)
  ... 51 elided
Caused by: java.io.FileNotFoundException: File file:/zeppelin/data/test.txt does not exist
  at org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)
  at org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)
  at org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)
  at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:142)
  at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:346)
  at org.apache.hadoop.fs.FileSystem.open(FileSystem.java:769)
  at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:109)
  at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.liftedTree1$1(HadoopRDD.scala:267)
  at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:266)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:224)
  at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:95)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
  at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
  at org.apache.spark.scheduler.Task.run(Task.scala:121)
  at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
  at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
  ... 3 more

 INFO [2020-02-19 08:10:38,897] ({pool-2-thread-2} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 08:10:38,935] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:120) - Job 20200219-065917_1853343063 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 WARN [2020-02-19 08:12:05,758] ({qtp395629617-15} SecurityRestApi.java[ticket]:88) - {"status":"OK","message":"","body":{"principal":"anonymous","ticket":"anonymous","roles":"[]"}}
 INFO [2020-02-19 08:12:05,844] ({qtp395629617-11} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 56726
 INFO [2020-02-19 08:13:06,100] ({qtp395629617-14} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 56726. (1006) WebSocket Read EOF
 INFO [2020-02-19 08:13:06,100] ({qtp395629617-13} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 56216. (1006) WebSocket Read EOF
 INFO [2020-02-19 08:13:44,850] ({qtp395629617-10} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 56882
 INFO [2020-02-19 08:13:44,936] ({qtp395629617-13} NotebookServer.java[sendNote]:828) - New operation from 172.30.0.1 : 56882 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 08:13:46,252] ({qtp395629617-13} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 08:13:46,254] ({qtp395629617-13} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:13:46,255] ({qtp395629617-13} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:13:46,257] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:13:46,259] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:13:46,263] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 08:13:46,264] ({qtp395629617-13} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 08:14:04,889] ({qtp395629617-10} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 56934
 INFO [2020-02-19 10:45:54,591] ({qtp395629617-10} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 56934. (1006) WebSocket Read EOF
 INFO [2020-02-19 10:45:54,591] ({qtp395629617-15} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 56882. (1006) WebSocket Read EOF
 INFO [2020-02-19 10:46:20,709] ({qtp395629617-16} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 47344
 INFO [2020-02-19 10:46:20,818] ({qtp395629617-14} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 47348
 INFO [2020-02-19 10:46:30,762] ({qtp395629617-16} NotebookServer.java[sendNote]:828) - New operation from 172.30.0.1 : 47348 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 10:46:30,877] ({qtp395629617-16} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 10:46:30,879] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 10:46:30,880] ({qtp395629617-16} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 10:46:30,881] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 10:46:30,882] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 10:46:30,883] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 10:46:30,884] ({qtp395629617-16} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 15:14:23,017] ({qtp395629617-10} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 47344. (1006) WebSocket Read EOF
 INFO [2020-02-19 15:14:23,019] ({qtp395629617-13} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 47348. (1006) WebSocket Read EOF
 INFO [2020-02-19 15:14:43,334] ({qtp395629617-11} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 51748
 INFO [2020-02-19 15:14:57,587] ({qtp395629617-15} NotebookServer.java[onOpen]:151) - New connection from 172.30.0.1 : 51782
 INFO [2020-02-19 15:15:02,816] ({qtp395629617-11} NotebookServer.java[sendNote]:828) - New operation from 172.30.0.1 : 51782 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 15:15:02,878] ({qtp395629617-11} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 15:15:02,886] ({qtp395629617-11} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 15:15:02,893] ({qtp395629617-11} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 15:15:02,894] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 15:15:02,896] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 15:15:02,908] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 15:15:02,911] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 16:14:07,993] ({qtp395629617-13} NotebookServer.java[sendNote]:828) - New operation from 172.30.0.1 : 51782 : anonymous : GET_NOTE : 2EZZ5HVRW
 WARN [2020-02-19 16:14:08,063] ({qtp395629617-13} GitNotebookRepo.java[revisionHistory]:158) - No Head found for 2EZZ5HVRW, No HEAD exists and no explicit starting revision was specified
 WARN [2020-02-19 16:14:08,074] ({qtp395629617-11} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 16:14:08,076] ({qtp395629617-11} InterpreterSettingManager.java[compare]:886) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 16:14:08,077] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 16:14:08,078] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 16:14:08,079] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 WARN [2020-02-19 16:14:08,081] ({qtp395629617-11} InterpreterSettingManager.java[compare]:892) - InterpreterGroup sap is not specified in zeppelin.interpreter.group.order
 INFO [2020-02-19 16:17:20,096] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:29,806] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:29,931] ({qtp395629617-15} NotebookServer.java[broadcastNewParagraph]:688) - Broadcasting paragraph on run call instead of note.
 INFO [2020-02-19 16:17:29,979] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:29,998] ({pool-2-thread-3} SchedulerFactory.java[jobStarted]:114) - Job 20200219-070050_1333640979 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 16:17:30,000] ({pool-2-thread-3} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-070050_1333640979, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 16:17:31,386] ({pool-2-thread-3} NotebookServer.java[afterStatusChange]:2316) - Job 20200219-070050_1333640979 is finished, status: ERROR, exception: null, result: %text import scala.io.Source
filename: String = /zeppelin/prueba3.txt
java.io.FileNotFoundException: /zeppelin/prueba3.txt (No such file or directory)
  at java.io.FileInputStream.open0(Native Method)
  at java.io.FileInputStream.open(FileInputStream.java:195)
  at java.io.FileInputStream.<init>(FileInputStream.java:138)
  at scala.io.Source$.fromFile(Source.scala:91)
  at scala.io.Source$.fromFile(Source.scala:76)
  at scala.io.Source$.fromFile(Source.scala:54)
  ... 52 elided

 INFO [2020-02-19 16:17:31,410] ({pool-2-thread-3} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:31,429] ({pool-2-thread-3} SchedulerFactory.java[jobFinished]:120) - Job 20200219-070050_1333640979 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 16:17:51,418] ({qtp395629617-16} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:51,567] ({qtp395629617-15} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:51,594] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:114) - Job 20200219-070050_1333640979 started by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 16:17:51,597] ({pool-2-thread-5} Paragraph.java[jobRun]:381) - Run paragraph [paragraph_id: 20200219-070050_1333640979, interpreter: , note_id: 2EZZ5HVRW, user: anonymous]
 WARN [2020-02-19 16:17:52,789] ({pool-6-thread-1} AppendOutputRunner.java[run]:104) - Processing size for buffered append-output is high: 508241 characters.
 INFO [2020-02-19 16:17:52,803] ({pool-2-thread-5} NotebookServer.java[afterStatusChange]:2314) - Job 20200219-070050_1333640979 is finished successfully, status: FINISHED
 INFO [2020-02-19 16:17:52,826] ({pool-2-thread-5} VFSNotebookRepo.java[save]:196) - Saving note:2EZZ5HVRW
 INFO [2020-02-19 16:17:52,885] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:120) - Job 20200219-070050_1333640979 finished by scheduler org.apache.zeppelin.interpreter.remote.RemoteInterpreter-spark:shared_process-shared_session
 INFO [2020-02-19 16:44:51,699] ({qtp395629617-13} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 51748. (1001) null
 INFO [2020-02-19 17:04:02,712] ({Thread-35} ZeppelinServer.java[run]:253) - Shutting down Zeppelin Server ... 
 INFO [2020-02-19 17:04:02,745] ({qtp395629617-10} NotebookServer.java[onClose]:372) - Closed connection to 172.30.0.1 : 51782. (1000) null
 INFO [2020-02-19 17:04:02,750] ({Thread-35} AbstractConnector.java[doStop]:341) - Stopped ServerConnector@fc807c1{HTTP/1.1,[http/1.1]}{0.0.0.0:8080}
 INFO [2020-02-19 17:04:02,759] ({Thread-35} HouseKeeper.java[stopScavenging]:167) - node0 Stopped scavenging
 INFO [2020-02-19 17:04:04,380] ({Thread-35} ContextHandler.java[doStop]:1045) - Stopped o.e.j.w.WebAppContext@1d548a08{zeppelin-web,/,null,UNAVAILABLE}{/zeppelin/zeppelin-web-0.8.2.war}
 INFO [2020-02-19 17:04:04,399] ({Thread-46} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 17:04:04,399] ({Thread-49} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 17:04:04,399] ({Thread-48} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 17:04:04,399] ({Thread-45} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 17:04:04,399] ({Thread-47} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 17:04:04,395] ({Thread-44} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 17:04:04,402] ({Thread-59} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 17:04:04,402] ({Thread-58} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 17:04:04,402] ({Thread-56} InterpreterSetting.java[close]:483) - Close InterpreterSetting: lens
 INFO [2020-02-19 17:04:04,402] ({Thread-54} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 17:04:04,402] ({Thread-55} InterpreterSetting.java[close]:483) - Close InterpreterSetting: jdbc
 INFO [2020-02-19 17:04:04,401] ({Thread-53} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sap
 INFO [2020-02-19 17:04:04,400] ({Thread-51} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 17:04:04,400] ({Thread-52} InterpreterSetting.java[close]:483) - Close InterpreterSetting: python
 INFO [2020-02-19 17:04:04,400] ({Thread-50} InterpreterSetting.java[close]:483) - Close InterpreterSetting: ignite
 INFO [2020-02-19 17:04:04,418] ({Thread-78} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 17:04:04,418] ({Thread-77} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 17:04:04,420] ({Thread-83} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 17:04:04,422] ({Thread-84} InterpreterSetting.java[close]:483) - Close InterpreterSetting: alluxio
 INFO [2020-02-19 17:04:04,417] ({Thread-75} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 17:04:04,416] ({Thread-76} InterpreterSetting.java[close]:483) - Close InterpreterSetting: md
 INFO [2020-02-19 17:04:04,416] ({Thread-73} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 17:04:04,416] ({Thread-74} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 17:04:04,416] ({Thread-72} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 17:04:04,416] ({Thread-69} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 17:04:04,414] ({Thread-71} InterpreterSetting.java[close]:483) - Close InterpreterSetting: cassandra
 INFO [2020-02-19 17:04:04,414] ({Thread-70} InterpreterSetting.java[close]:483) - Close InterpreterSetting: redshift
 INFO [2020-02-19 17:04:04,411] ({Thread-62} InterpreterSetting.java[close]:483) - Close InterpreterSetting: elasticsearch
 INFO [2020-02-19 17:04:04,411] ({Thread-68} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 17:04:04,411] ({Thread-67} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 17:04:04,411] ({Thread-60} InterpreterSetting.java[close]:483) - Close InterpreterSetting: file
 INFO [2020-02-19 17:04:04,411] ({Thread-66} InterpreterSetting.java[close]:483) - Close InterpreterSetting: neo4j
 INFO [2020-02-19 17:04:04,410] ({Thread-61} InterpreterSetting.java[close]:483) - Close InterpreterSetting: groovy
 INFO [2020-02-19 17:04:04,410] ({Thread-65} InterpreterSetting.java[close]:483) - Close InterpreterSetting: livy
 INFO [2020-02-19 17:04:04,410] ({Thread-64} InterpreterSetting.java[close]:483) - Close InterpreterSetting: angular
 INFO [2020-02-19 17:04:04,410] ({Thread-63} InterpreterSetting.java[close]:483) - Close InterpreterSetting: flink
 INFO [2020-02-19 17:04:04,410] ({Thread-57} InterpreterSetting.java[close]:483) - Close InterpreterSetting: pig
 INFO [2020-02-19 17:04:04,426] ({Thread-73} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 17:04:04,425] ({Thread-87} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 17:04:04,425] ({Thread-86} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 17:04:04,424] ({Thread-85} InterpreterSetting.java[close]:483) - Close InterpreterSetting: bigquery
 INFO [2020-02-19 17:04:04,420] ({Thread-82} InterpreterSetting.java[close]:483) - Close InterpreterSetting: spark
 INFO [2020-02-19 17:04:04,420] ({Thread-79} InterpreterSetting.java[close]:483) - Close InterpreterSetting: sh
 INFO [2020-02-19 17:04:04,419] ({Thread-81} InterpreterSetting.java[close]:483) - Close InterpreterSetting: kylin
 INFO [2020-02-19 17:04:04,419] ({Thread-80} InterpreterSetting.java[close]:483) - Close InterpreterSetting: hbase
 INFO [2020-02-19 17:04:04,439] ({Thread-73} ManagedInterpreterGroup.java[close]:100) - Close Session: shared_session for interpreter setting: spark
 WARN [2020-02-19 17:04:04,646] ({Thread-73} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkSqlInterpreter
 WARN [2020-02-19 17:04:04,647] ({Thread-73} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.DepInterpreter
 WARN [2020-02-19 17:04:04,654] ({Thread-73} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.PySparkInterpreter
 WARN [2020-02-19 17:04:04,657] ({Thread-73} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.IPySparkInterpreter
 WARN [2020-02-19 17:04:04,658] ({Thread-73} RemoteInterpreter.java[close]:199) - close is called when RemoterInterpreter is not opened for org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-02-19 17:04:04,669] ({Thread-73} ManagedInterpreterGroup.java[close]:105) - Remove this InterpreterGroup: spark:shared_process as all the sessions are closed
 INFO [2020-02-19 17:04:04,670] ({Thread-73} ManagedInterpreterGroup.java[close]:108) - Kill RemoteInterpreterProcess
 INFO [2020-02-19 17:04:04,671] ({Thread-73} RemoteInterpreterManagedProcess.java[stop]:220) - Kill interpreter process
ERROR [2020-02-19 17:04:05,437] ({Thread-37} RemoteInterpreterEventPoller.java[run]:257) - Can not get RemoteInterpreterEvent because it is shutdown.
ERROR [2020-02-19 17:04:05,443] ({pool-6-thread-1} AppendOutputRunner.java[run]:68) - Wait for OutputBuffer queue interrupted: null
 WARN [2020-02-19 17:04:07,510] ({Thread-73} RemoteInterpreterManagedProcess.java[stop]:230) - ignore the exception when shutting down
 INFO [2020-02-19 17:04:07,513] ({Thread-73} RemoteInterpreterManagedProcess.java[stop]:238) - Remote process terminated
 INFO [2020-02-19 17:04:07,514] ({Thread-82} ManagedInterpreterGroup.java[close]:89) - Close InterpreterGroup: spark:shared_process
 INFO [2020-02-19 17:04:07,514] ({Thread-35} NotebookRepoSync.java[close]:428) - Closing all notebook storages
 INFO [2020-02-19 17:04:07,530] ({Exec Default Executor} RemoteInterpreterManagedProcess.java[onProcessFailed]:250) - Interpreter process failed {}
org.apache.commons.exec.ExecuteException: Process exited with an error: 143 (Exit value: 143)
	at org.apache.commons.exec.DefaultExecutor.executeInternal(DefaultExecutor.java:404)
	at org.apache.commons.exec.DefaultExecutor.access$200(DefaultExecutor.java:48)
	at org.apache.commons.exec.DefaultExecutor$1.run(DefaultExecutor.java:200)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2020-02-19 17:04:10,536] ({Thread-35} ZeppelinServer.java[run]:264) - Bye
